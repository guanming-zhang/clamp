{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.4 (you have 1.4.23). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 4\n",
      "prefetch_factor = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = ddp\n",
      "if_profile = False\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 8\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "augmentation_package = albumentations\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 3\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "use_projection_head = True\n",
      "proj_dim = [4096]\n",
      "proj_out_dim = 512\n",
      "optimizer = LARS\n",
      "lr = 12.2\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine-warmup\n",
      "grad_accumulation_steps = 1\n",
      "momentum = 0.0\n",
      "weight_decay = 0.0001\n",
      "lars_eta = 0.001\n",
      "loss_function = RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.0\n",
      "pot_pow = 1.0\n",
      "max_mem_size = 64\n",
      "max_grad_norm = -1.0\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 2\n",
      "batch_size = 8\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = Adam\n",
      "use_batch_norm = False\n",
      "lr_sweep = [0.3, 0.1, 0.05]\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = -1.0\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 100\n",
      "save_every_n_epochs = 50\n",
      "batch_size = 1024\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "restart_training = False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625\n",
      "625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"]*config.SSL[\"grad_accumulation_steps\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,\n",
    "                                                                                num_workers = config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                standardized_to_imagenet=True,\n",
    "                                                                                augment_val_set = True,\n",
    "                                                                                prefetch_factor=config.INFO[\"prefetch_factor\"],\n",
    "                                                                                aug_pkg = config.DATA[\"augmentation_package\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))\n",
    "print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# check if the sub module is the same as needed\\nfor name, module in ssl_model.backbone.named_modules():\\n    print(name, \":\", module)\\n# check if the bachnorm is correctly converted to sync batchnorm\\n\\n\\nssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\\nfor name, module in ssl_model.backbone.named_modules():\\n    if isinstance(module, torch.nn.BatchNorm2d):\\n        print(f\"No BatchNorm2d NOT converted at: {name}\")\\n    elif isinstance(module, torch.nn.SyncBatchNorm):\\n        print(f\"Yes SyncBatchNorm converted at: {name}\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  loss_name= config.SSL[\"loss_function\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  scheduler_name = config.SSL[\"lr_scheduler\"],\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = ssl_batch_size,\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  max_mem_size = config.SSL[\"max_mem_size\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])\n",
    "'''\n",
    "# check if the sub module is the same as needed\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    print(name, \":\", module)\n",
    "# check if the bachnorm is correctly converted to sync batchnorm\n",
    "\n",
    "\n",
    "ssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        print(f\"No BatchNorm2d NOT converted at: {name}\")\n",
    "    elif isinstance(module, torch.nn.SyncBatchNorm):\n",
    "        print(f\"Yes SyncBatchNorm converted at: {name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/ssl exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 15.4 M | train\n",
      "-------------------------------------------------\n",
      "15.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 M    Total params\n",
      "61.471    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "152f4aa4bd0543be999c207f4a140d11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_grad_norm=config.SSL[\"max_grad_norm\"],\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "    ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = ssl_model.backbone.feature_dim,\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "                results = json.load(f)\n",
    "                best_lc_dir = results[\"best_model_dir\"] \n",
    "            lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= lc_model.linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transfer learning(freeze backbone)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mTL) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     tl_output_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m101\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m102\u001b[39m}\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = ssl_model.backbone.feature_dim,\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
