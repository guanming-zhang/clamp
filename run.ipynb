{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.24 (you have 1.4.23). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 4\n",
      "prefetch_factor = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = auto\n",
      "if_profile = True\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 16\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "augmentation_package = torchvision\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 1\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "backbone_out_dim = 2048\n",
      "use_projection_head = True\n",
      "proj_dim = 2048\n",
      "proj_out_dim = 128\n",
      "optimizer = LARS\n",
      "lr = 0.8\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine-warmup\n",
      "grad_accumulation_steps = 1\n",
      "momentum = 0.0\n",
      "weight_decay = 0.0001\n",
      "lars_eta = 0.001\n",
      "loss_function = EllipsoidPackingLoss\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.0\n",
      "pot_pow = 1.0\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 5\n",
      "batch_size = 64\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = SGD\n",
      "use_batch_norm = False\n",
      "lr = 0.2\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = 0.9\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 6\n",
      "save_every_n_epochs = 3\n",
      "batch_size = 256\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "restart_training = False\n",
      "lr_sweep = [0.1, 0.2, 0.3]\n",
      "\n",
      "lr overrided by lr_sweep!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n",
      "78\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"]*config.SSL[\"grad_accumulation_steps\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,\n",
    "                                                                                num_workers = config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                standardized_to_imagenet=False,\n",
    "                                                                                augment_val_set = True,\n",
    "                                                                                prefetch_factor=config.INFO[\"prefetch_factor\"],\n",
    "                                                                                aug_pkg = config.DATA[\"augmentation_package\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))\n",
    "print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  backbone_out_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  scheduler_name = config.SSL[\"lr_scheduler\"],\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = config.SSL[\"batch_size\"],\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory ./simulations/ssl/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/ssl exists and is not empty.\n",
      "Restoring states from the checkpoint path at ./simulations/ssl/ssl-epoch=1.ckpt\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 16.7 M | train\n",
      "-------------------------------------------------\n",
      "16.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.7 M    Total params\n",
      "66.712    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n",
      "Restored all states from the checkpoint at ./simulations/ssl/ssl-epoch=1.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading ...../simulations/ssl/ssl-epoch=1.ckpt\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e0c070afde64014b5351df3a4a540b1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1659c20869f2464080f2a1dba7b4918c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/amp.py:78\u001b[0m, in \u001b[0;36mMixedPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MisconfigurationException(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAMP and the LBFGS optimizer are not compatible.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 78\u001b[0m closure_result \u001b[38;5;241m=\u001b[39m \u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     80\u001b[0m \u001b[38;5;66;03m# If backward was skipped in automatic optimization (return None), unscaling is not needed\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:144\u001b[0m, in \u001b[0;36mClosure.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Tensor]:\n\u001b[0;32m--> 144\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\u001b[38;5;241m.\u001b[39mloss\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:129\u001b[0m, in \u001b[0;36mClosure.closure\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;129m@override\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;129m@torch\u001b[39m\u001b[38;5;241m.\u001b[39menable_grad()\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mclosure\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs: Any, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ClosureResult:\n\u001b[0;32m--> 129\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m step_output\u001b[38;5;241m.\u001b[39mclosure_loss \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:317\u001b[0m, in \u001b[0;36m_AutomaticOptimization._training_step\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    315\u001b[0m trainer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\n\u001b[0;32m--> 317\u001b[0m training_step_output \u001b[38;5;241m=\u001b[39m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_strategy_hook\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtraining_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mpost_training_step()  \u001b[38;5;66;03m# unused hook - call anyway for backward compatibility\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:319\u001b[0m, in \u001b[0;36m_call_strategy_hook\u001b[0;34m(trainer, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[Strategy]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 319\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    321\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:390\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    389\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_redirection(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_step\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m--> 390\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlightning_module\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/clap/model/lightning_models.py:128\u001b[0m, in \u001b[0;36mCLAP.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[38;5;66;03m# the labels are dummy since label is not used in ssl\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpreds\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtrain_step_outputs\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mdetach())\n",
      "File \u001b[0;32m~/Documents/code/clap/model/loss_module.py:76\u001b[0m, in \u001b[0;36mEllipsoidPackingLoss.__call__\u001b[0;34m(self, preds, labels)\u001b[0m\n\u001b[1;32m     75\u001b[0m mask \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlogical_and(nbr_mask,torch\u001b[38;5;241m.\u001b[39mlogical_not(self_mask))\n\u001b[0;32m---> 76\u001b[0m ll \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.5\u001b[39m\u001b[38;5;241m*\u001b[39m((\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdist_matrix\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43msum_radii\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m]\u001b[49m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpot_pow)\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlw1\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mabs\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlw0) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1e-6\u001b[39m:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;66;03m# loss 0: minimize the size of each ellipsoids\u001b[39;00m\n\u001b[1;32m     79\u001b[0m     \u001b[38;5;66;03m# to make sure radii =0 and dij = inf is not a valid state \u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/_tensor.py:34\u001b[0m, in \u001b[0;36m_handle_torch_function_and_wrap_type_error_to_not_implemented.<locals>.wrapped\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     32\u001b[0m assigned \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mWRAPPER_ASSIGNMENTS\n\u001b[0;32m---> 34\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(f, assigned\u001b[38;5;241m=\u001b[39massigned)\n\u001b[1;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     37\u001b[0m         \u001b[38;5;66;03m# See https://github.com/pytorch/pytorch/issues/75462\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(ssl_dir):\n\u001b[1;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(ssl_dir)\n\u001b[0;32m----> 4\u001b[0m ssl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_clap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mssl_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mssl_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mevery_n_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_every_n_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mif_profile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mif_profile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/clap/model/lightning_models.py:236\u001b[0m, in \u001b[0;36mtrain_clap\u001b[0;34m(model, train_loader, val_loader, max_epochs, every_n_epochs, checkpoint_path, grad_accumulation_steps, num_nodes, gpus_per_node, strategy, precision, restart, if_profile)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ckpt_files \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m restart):\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading ....\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m ckpt_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m--> 236\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_files\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    238\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(model, train_loader,val_loader)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b163edae-f73e-4982-a53d-89e00a2d031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulation_imagenet/ssl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssl_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.1/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.2/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.3/best_val.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "    ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulation_imagenet/lc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.1/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.2/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.3/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.1/best_val.ckpt, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory ./simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.2/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 27.7 M | train\n",
      "1 | linear_net | BnLinearNet | 2.1 M  | train\n",
      "---------------------------------------------------\n",
      "29.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 M    Total params\n",
      "119.030   Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ab7adb337646ae9e7acbcb2fa37553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f164359336b471eb21ca5c62e8a70da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1       0.0013404289493337274\n",
      "     batch_test_acc5        0.00616197194904089\n",
      "     batch_test_loss         8.386237144470215\n",
      "        test_acc1          0.0013404289493337274\n",
      "        test_acc5           0.00616197194904089\n",
      "        test_loss            8.386237144470215\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 27.7 M | train\n",
      "1 | linear_net | BnLinearNet | 2.1 M  | train\n",
      "---------------------------------------------------\n",
      "29.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 M    Total params\n",
      "119.030   Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb217f39bf3e4dda931b17222be0b107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2541fb439a19467fb2a7db0040b65332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1       0.001260403310880065\n",
      "     batch_test_acc5       0.004921575076878071\n",
      "     batch_test_loss         9.744197845458984\n",
      "        test_acc1          0.001260403310880065\n",
      "        test_acc5          0.004921575076878071\n",
      "        test_loss            9.744195938110352\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "                results = json.load(f)\n",
    "                best_lc_dir = results[\"best_model_dir\"] \n",
    "            lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= lc_model.linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transfer learning(freeze backbone)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mTL) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     tl_output_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m101\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m102\u001b[39m}\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
