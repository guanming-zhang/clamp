{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.8 (you have 1.4.23). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[KNN]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[KNN]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 4\n",
      "prefetch_factor = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = auto\n",
      "if_profile = False\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 4\n",
      "n_trans = 1\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "augmentation_package = albumentations\n",
      "crop_size = [32]\n",
      "crop_min_scale = [0.08]\n",
      "crop_max_scale = [1.0]\n",
      "hflip_prob = [0.5]\n",
      "blur_kernel_size = [3]\n",
      "blur_prob = [0.5]\n",
      "grayscale_prob = [0.2]\n",
      "jitter_brightness = [0.8]\n",
      "jitter_contrast = [0.8]\n",
      "jitter_saturation = [0.8]\n",
      "jitter_hue = [0.2]\n",
      "jitter_prob = [0.8]\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "use_projection_head = True\n",
      "proj_dim = [2048]\n",
      "proj_out_dim = 256\n",
      "use_momentum_encoder = True\n",
      "momentum_coefficient = 0.9\n",
      "optimizer = LARS\n",
      "lr = 0.1\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine-warmup-restart\n",
      "momentum = 0.9\n",
      "weight_decay = 1e-06\n",
      "exclude_bn_bias_from_weight_decay = True\n",
      "scale_weight_decay = True\n",
      "lars_eta = 0.001\n",
      "loss_function = LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.0\n",
      "pot_pow = 2.0\n",
      "n_restart = 2\n",
      "rs = 3.0\n",
      "warmup_epochs = 2\n",
      "n_epochs = 4\n",
      "batch_size = 8\n",
      "save_every_n_epochs = 2\n",
      "skip_validation = False\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = Adam\n",
      "use_batch_norm = False\n",
      "lr_sweep = [0.3, 0.1, 0.05]\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = -1.0\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 2\n",
      "save_every_n_epochs = 5\n",
      "batch_size = 16\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(<Figure size 640x480 with 4 Axes>,\n",
       " array([[<Axes: >, <Axes: >],\n",
       "        [<Axes: >, <Axes: >]], dtype=object))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,\n",
    "                                                                                num_workers = config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                standardized_to_imagenet=True,\n",
    "                                                                                augment_val_set = True,\n",
    "                                                                                prefetch_factor=config.INFO[\"prefetch_factor\"],\n",
    "                                                                                aug_pkg = config.DATA[\"augmentation_package\"],\n",
    "                                                                                skip_validation = config.SSL[\"skip_validation\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "#print(len(ssl_train_loader))\n",
    "#print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nconfig.SSL[\"exclude_bn_bias_from_weight_decay\"]\\n# check if the sub module is the same as needed\\nfor name, module in ssl_model.backbone.named_modules():\\n    print(name, \":\", module)\\n# check if the bachnorm is correctly converted to sync batchnorm\\n\\n\\nssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\\nfor name, module in ssl_model.backbone.named_modules():\\n    if isinstance(module, torch.nn.BatchNorm2d):\\n        print(f\"No BatchNorm2d NOT converted at: {name}\")\\n    elif isinstance(module, torch.nn.SyncBatchNorm):\\n        print(f\"Yes SyncBatchNorm converted at: {name}\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAMP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  use_momentum_encoder = config.SSL[\"use_momentum_encoder\"],\n",
    "                                  momentum_coeff = config.SSL[\"momentum_coefficient\"],\n",
    "                                  loss_name= config.SSL[\"loss_function\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  scheduler_name = config.SSL[\"lr_scheduler\"],\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_restart = config.SSL[\"n_restart\"],\n",
    "                                  exclude_bn_bias_from_weight_decay  =  config.SSL[\"exclude_bn_bias_from_weight_decay\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = ssl_batch_size,\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])\n",
    "'''\n",
    "config.SSL[\"exclude_bn_bias_from_weight_decay\"]\n",
    "# check if the sub module is the same as needed\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    print(name, \":\", module)\n",
    "# check if the bachnorm is correctly converted to sync batchnorm\n",
    "\n",
    "\n",
    "ssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        print(f\"No BatchNorm2d NOT converted at: {name}\")\n",
    "    elif isinstance(module, torch.nn.SyncBatchNorm):\n",
    "        print(f\"Yes SyncBatchNorm converted at: {name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory ./simulations/ssl/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clamp/simulations/ssl exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name              | Type        | Params | Mode \n",
      "----------------------------------------------------------\n",
      "0 | backbone          | BackboneNet | 12.7 M | train\n",
      "1 | momentum_backbone | BackboneNet | 12.7 M | train\n",
      "----------------------------------------------------------\n",
      "12.7 M    Trainable params\n",
      "12.7 M    Non-trainable params\n",
      "25.5 M    Total params\n",
      "101.952   Total estimated model params size (MB)\n",
      "146       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dea2b1c88bde45d29434c38173968d93",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clamp(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58125fe9-0b8d-4f23-87c6-8ce3b733ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_ckpt = os.path.join(ssl_dir,\"last_epoch_backbone_\" + config.SSL[\"backbone\"] +\".ckpt\")\n",
    "if not os.path.isfile(backbone_ckpt):\n",
    "    torch.save(ssl_model.backbone.net.state_dict(),backbone_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clamp/simulations/lc/lr_0.3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68815ebf34654f95adaa2d0990b278d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: simulations/lc/lr_0.3/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1893a7f1603e43c48b4b4b1fd54b474e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.3174000084400177\n",
      "     batch_test_acc5         0.807200014591217\n",
      "     batch_test_loss         2.098980188369751\n",
      "        test_acc1           0.3173999786376953\n",
      "        test_acc5           0.8071999549865723\n",
      "        test_loss           2.0989792346954346\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clamp/simulations/lc/lr_0.1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf8b4691510a4f2facda5c0a93dfa188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: simulations/lc/lr_0.1/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec879cc9d7df42b781481db679b070cd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.27480000257492065\n",
      "     batch_test_acc5        0.8400999903678894\n",
      "     batch_test_loss         2.09466552734375\n",
      "        test_acc1           0.27480000257492065\n",
      "        test_acc5           0.8400999903678894\n",
      "        test_loss            2.094666004180908\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clamp/simulations/lc/lr_0.05 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4d6ccf0c121840259cc4ef80bc9ce683",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: simulations/lc/lr_0.05/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f7b1eac48edc4e8e8ea9fad6f1964770",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.34150001406669617\n",
      "     batch_test_acc5        0.8253999948501587\n",
      "     batch_test_loss        1.8564646244049072\n",
      "        test_acc1           0.3414999842643738\n",
      "        test_acc5           0.8253999948501587\n",
      "        test_loss           1.8564640283584595\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"n_trans\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":[config.DATA[\"crop_size\"][0]],\"crop_min_scale\":[0.08],\"crop_max_scale\":[1.0],\"hflip_prob\":[0.5]}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    latest_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "    ssl_model = lightning_models.CLAMP.load_from_checkpoint(latest_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = ssl_model.backbone.feature_dim,\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lc_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlc_dir\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lc_dir' is not defined"
     ]
    }
   ],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'scheduler_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# load the best linear classifier from the checkpoint\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#with open(os.path.join(lc_dir,\"results.json\")) as f:\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#    results = json.load(f)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#    best_lc_dir = results[\"best_model_dir\"] \u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m linear_net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2048\u001b[39m,\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m semisl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFineTune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mssl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlinear_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptim_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msemisl_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m semisl_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mtrain_finetune(\n\u001b[1;32m     55\u001b[0m         finetune_model \u001b[38;5;241m=\u001b[39m semisl_model,\n\u001b[1;32m     56\u001b[0m         train_loader \u001b[38;5;241m=\u001b[39m semisl_test_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m         precision\u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mINFO[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     63\u001b[0m         restart \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mSemiSL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestart_training\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# get the best performed one\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'scheduler_name'"
     ]
    }
   ],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\n",
    "                     \"batch_size\":semisl_batch_size,\n",
    "                     \"n_views\":1,\n",
    "                     \"n_trans\":1,\n",
    "                     \"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                     \"crop_size\":config.DATA[\"crop_size\"],\n",
    "                     \"crop_min_scale\":[0.08],\n",
    "                     \"crop_max_scale\":[1.0],\n",
    "                     \"hflip_prob\":[0.5]}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            latest_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "            ssl_model = lightning_models.CLAMP.load_from_checkpoint(latest_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            #with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "            #    results = json.load(f)\n",
    "            #    best_lc_dir = results[\"best_model_dir\"] \n",
    "            #lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            linear_net = torch.nn.Linear(2048,1000)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'mean4norm': [0.5071, 0.4867, 0.4408], 'std4norm': [0.2675, 0.2565, 0.2761], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.1/best_val.ckpt, loading...\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.1/best_val.ckpt, loading...\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.1/best_val.ckpt, loading...\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.1/best_val.ckpt, loading...\n",
      "Using downloaded and verified file: ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar\n",
      "Extracting ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar to ./datasets/pascalvoc\n",
      "Using downloaded and verified file: ./datasets/pascalvoc/VOCtest_06-Nov-2007.tar\n",
      "Extracting ./datasets/pascalvoc/VOCtest_06-Nov-2007.tar to ./datasets/pascalvoc\n",
      "Using downloaded and verified file: ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar\n",
      "Extracting ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar to ./datasets/pascalvoc\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/lightning_fabric/loggers/csv_logs.py:269: Experiment logs directory ./simulation_imagenet/tl-PascalVOC/lr_0.005/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 23.5 M | train\n",
      "1 | linear_net | Linear      | 41.0 K | train\n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.196    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda31decb7b24747959ddb21ea1611ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 183, in collate\n    clone[i] = collate(samples, collate_fn_map=collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 170, in collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m\n\u001b[1;32m     41\u001b[0m ssl_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mremove_projection_head()\n\u001b[1;32m     43\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mLinearClassification(\n\u001b[1;32m     44\u001b[0m         backbone \u001b[38;5;241m=\u001b[39m ssl_model\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[1;32m     45\u001b[0m         in_dim \u001b[38;5;241m=\u001b[39m ssl_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mfeature_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m         weight_decay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     53\u001b[0m         n_epochs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 55\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_lc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevery_n_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_every_n_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_sub_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrestart_training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     65\u001b[0m             \u001b[38;5;66;03m# get the best performed one\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tl_sub_dir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Documents/clap/model/lightning_models.py:600\u001b[0m, in \u001b[0;36mtrain_lc\u001b[0;34m(linear_model, train_loader, test_loader, val_loader, max_epochs, every_n_epochs, checkpoint_path, num_nodes, gpus_per_node, strategy, precision, restart, if_profile)\u001b[0m\n\u001b[1;32m    598\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(linear_model, train_loader,val_loader,ckpt_path\u001b[38;5;241m=\u001b[39mckpt_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# load the model with the best validation accuracy to avoid overfitting\u001b[39;00m\n\u001b[1;32m    602\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearClassification\u001b[38;5;241m.\u001b[39mload_from_checkpoint(trained_filename,backbone \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mbackbone) \u001b[38;5;66;03m# Load best checkpoint after training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1028\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1028\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1030\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1057\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1057\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 183, in collate\n    clone[i] = collate(samples, collate_fn_map=collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 170, in collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102,\n",
    "                    \"DTD\":47}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\",\"DTD\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\n",
    "                     \"batch_size\":tl_batch_size,\n",
    "                     \"n_views\":1,\n",
    "                     \"n_trans\":1,\n",
    "                     \"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                     \"crop_size\":config.DATA[\"crop_size\"],\n",
    "                     \"crop_min_scale\":[0.08],\n",
    "                     \"crop_max_scale\":[1.0],\n",
    "                     \"hflip_prob\":[0.5]}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,batch_size=10,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            latest_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "            ssl_model = lightning_models.CLAMP.load_from_checkpoint(latest_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = ssl_model.backbone.feature_dim,\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
