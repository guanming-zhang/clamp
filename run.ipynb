{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "num_workers = 8\n",
      "precision = 16-mixed\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 4\n",
      "augmentations = ['RandomResizeCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 1\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet34\n",
      "backbone_out_dim = 256\n",
      "use_projection_header = True\n",
      "proj_out_dim = 2048\n",
      "optimizer = LARS\n",
      "lr = 0.0005\n",
      "lr_scale = linear\n",
      "momentum = 0.99\n",
      "weight_decay = 0.0001\n",
      "lars_eta = 0.1\n",
      "loss_function = EllipsoidPackingLoss\n",
      "lw0 = 1.0\n",
      "lw1 = 1.0\n",
      "lw2 = 1.0\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 3\n",
      "batch_size = 32\n",
      "save_every_n_epochs = 10\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = SGD\n",
      "use_batch_norm = True\n",
      "lr = 0.01\n",
      "lr_scale = linear\n",
      "weight_decay = 0.1\n",
      "momentum = 0.99\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 3\n",
      "batch_size = 128\n",
      "\n",
      "[IO]\n",
      "restart = True\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",defalut_config_file=\"./default_config_cifar10.ini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1406\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAHVCAYAAAAZ7zmqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy81sbWrAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAOu0lEQVR4nO3dz4uVZR/H8XPUcXRMIUudyYKooKQfkowQhBQlhBEERQVuoj+hFu1aVH9BFBS1q42LNhG0qYUVtmj6gWBGPyBzyCjJSVNntHHOs3l4eKD7e3NmmqMzn3m9ltd37pl7mvG854ZzdXV7vV6vAwBEWnWlbwAAGByhB4BgQg8AwYQeAIIJPQAEE3oACCb0ABBM6AEg2Jp+P7Db7Q7yPoBOp5P0/6/ymgGD189rhid6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAjW7fV6vSt9EwDAYHiiB4BgQg8AwYQeAIIJPQAEE3oACCb0ABBM6AEgmNADQDChB4BgQg8AwYQeAIIJPQAEE3oACCb0ABBsTb8f6DTbxXH+/PlyNjIychnvhKWo2+1e6VtYNEnfCyxV/bTZEz0ABBN6AAgm9AAQTOgBIJjQA0Cwvt91z+KYnJwsZ7fcckvj+urVqwd1O/xX2ztX22aXLl2a9zWrVtV/Xw8NDZUzgIXwRA8AwYQeAIIJPQAEE3oACCb0ABBM6AEgmO11l9nnn39ezsbGxhrXN23aNKjbWZbm5ubKWdu2trZtim0HsCxk693Zs2fLa6oteZ1Op7N169ZyBrAQnugBIJjQA0AwoQeAYEIPAMGEHgCCedf9ZXbw4MFyVr27/tFHHx3Q3SxPbe+Qv3DhQjlbt25dOVvooTbVvbR9rb/++qucASw2T/QAEEzoASCY0ANAMKEHgGBCDwDBhB4AgvW9ve7ixYvlrO2QkWr70Zo19ZduO3ykTdtBIufPn29cH8QhIjMzM+Xs9OnT5Wx2dnbR72UxtR3G0vY70DYbGhoqZ6tWNf8d2ra9ru3z/f333+WsbQtd25a96h7bvue2rXcAi80TPQAEE3oACCb0ABBM6AEgmNADQDChB4Bg3V7bvqL//8CWLU3L2VVXXVXOqq1TnU6ns3nz5nLWtg1tcnKynO3cubNx/dZbby2vWbt2bTlr+962bdtWzioL3fbYtp1sy5Yt5aza+ti2ha7t17ltS+dCT8SrfkdGRkbKazZu3FjOqt+B5Sj1NQOWkn4S7okeAIIJPQAEE3oACCb0ABBM6AEgmNADQLAVv70OBqFt++LVV19dzr799ttB3M4V4TUDBs/2OgBY4YQeAIIJPQAEE3oACCb0ABBM6AEg2KJsr2s7Ja3SdsLb9PT0vD8f//T000+Xs7YT1L755pvG9WPHjpXX/PTTT33fF7U+/zkuC7bXweDZXgcAK5zQA0AwoQeAYEIPAMGEHgCCren3A8fHx8tZ2yEdp06dalxve6f+xx9/3O9t0eKGG24oZ9dff30527t3b+N6289sYmKinP3yyy/l7J577ilnX331VeP6wYMHy2u+/vrrcpb0jnaAfnmiB4BgQg8AwYQeAIIJPQAEE3oACCb0ABCs70NthoeHy1nbtqtqex10Op3Oiy++WM727dvXuN72u9h2INIHH3xQzl566aVydjklbQF0qA0MnkNtAGCFE3oACCb0ABBM6AEgmNADQDChB4BgfW+vs1WGpWLt2rXlbGxsrJxNTk6Ws7m5uX91T4vF9jpgPmyvA4AVTugBIJjQA0AwoQeAYEIPAMGEHgCC2V7HP4yMjDSut/2qtJ0aR/9srwPmw/Y6AFjhhB4Aggk9AAQTegAIJvQAEEzoASDYmit9A/w7+/fvL2cPPfRQOXvzzTfL2dTUVOP60aNH+78xAJYET/QAEEzoASCY0ANAMKEHgGBCDwDBhB4Agtlet8wNDw+Xs/fff7+cHTp0aN5fa9OmTeXszJkz8/58AAyeJ3oACCb0ABBM6AEgmNADQDChB4BgK/5d92+99VY5e+2118rZ4cOHB3E7jUZHR8vZjz/+WM4+/fTTRb2Pxx57rJxdunSpnL3zzjvl7Oabby5nO3bsaFw/fvx4ec2RI0fK2dzcXDkDSOWJHgCCCT0ABBN6AAgm9AAQTOgBIJjQA0CwFbO97o477mhc379/f3nN2bNny9mzzz77r++pX08++WQ5a7vHxd5ed+ONN5az559/vpw999xz5ezOO+8sZ6tWzf/v0HPnzpWzZ555ppy9++678/5aAMuBJ3oACCb0ABBM6AEgmNADQDChB4BgQg8AwVbM9rpHHnmkcX39+vXlNbt37x7U7TRau3Zt4/p1111XXnPfffeVs9nZ2XL29ttvl7Px8fHG9bZtfuvWrStnO3fuLGdter3evK8ZGRkpZ9u3b1/QfQAsZ57oASCY0ANAMKEHgGBCDwDBhB4Aggk9AARbMdvrqi1jC73m/vvvL2dHjx4tZ3v27Cln+/bta1x/+OGHy2tGR0fLWdtpc9XXavt6GzduLK9pc+LEiXI2MTFRzjZs2NC4vmXLlvKaAwcOlLPXX3+9nAGk8kQPAMGEHgCCCT0ABBN6AAgm9AAQTOgBIFi31+cRYd1ud9D3MlBffPFF4/quXbsW9PlOnjxZzs6dO1fO2ra8LXV//PFHOTt06NCCZp999lk5+/333xvXL1y4UF5z/PjxcrYcLOTEvqVqub9mwHLQz2uGJ3oACCb0ABBM6AEgmNADQDChB4BgUYfabNu2rZx9+eWXjeuTk5PlNb/++ms527t3bzm76aabylnbO8aHh4fLWaXtnfDVu9Y7nU7n559/LmeHDx9uXD9y5Eh5Tds7648dO1bOlru77rqrcf3xxx8vr2n7uQAsNk/0ABBM6AEgmNADQDChB4BgQg8AwYQeAIJFba/77bffytknn3zSuN621enDDz8sZw8++GA5azsoZ2hoqJxV2/JmZmbKa9q+5xMnTpSzH374oZx9//33jeunT58ur5meni5ny92BAwfK2d133924/t1335XXvPrqq//6ngD65YkeAIIJPQAEE3oACCb0ABBM6AEgmNADQLBur9fr9fWB3e6g72Wg9uzZ07g+NTVVXtN2WlubrVu3lrN77723nD311FON62NjY+U111xzTTlr+9FevHixnF26dKlx/cyZM+U11emAnU77NsWPPvqonF1OL7/8cjnbsGFDOXvllVca19tOB2zT5z/HZWG5v2bActDPa4YnegAIJvQAEEzoASCY0ANAMKEHgGBCDwDBok6va7N9+/bG9d27d5fXjIyMlLPh4eFytmPHjnI2Pj5ezm6//fZ5f75Vq5bG32q33XZbOVu/fn05W716dTmbmJhoXD916lT/N9anF154YdE/J8BSsDQqAQAMhNADQDChB4BgQg8AwYQeAIIJPQAEG/j2ugceeKBx/YknniivaduC1radbM2a+tsZHR1tXG87/W16erqctWk77Ww5azu97o033ihn7733Xjk7efJkORvENjqAlcYTPQAEE3oACCb0ABBM6AEgmNADQLBur9fr9fWB3e6g7+V/rr322nK2a9eucrZ58+ZyNjQ01LjedjhN23+amZmZBc3a3slfXXfx4sXymj///LOcTU1NlbO27/v48eON67Ozs+U1LI4+/zkuC5fzNQNWqn5eMzzRA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAi2JLfXwUplex0wH7bXAcAKJ/QAEEzoASCY0ANAMKEHgGBCDwDBhB4Aggk9AAQTegAIJvQAEEzoASCY0ANAMKEHgGBCDwDBhB4Aggk9AAQTegAIJvQAEEzoASCY0ANAMKEHgGBCDwDBhB4Aggk9AAQTegAIJvQAEEzoASCY0ANAMKEHgGBCDwDBhB4Aggk9AAQTegAIJvQAEEzoASCY0ANAMKEHgGBCDwDBhB4Aggk9AAQTegAIJvQAEEzoASCY0ANAMKEHgGBCDwDBhB4AgnV7vV7vSt8EADAYnugBIJjQA0AwoQeAYEIPAMGEHgCCCT0ABBN6AAgm9AAQTOgBINh/AOHySPdLSQo8AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "\n",
    "ssl_train_loader,lc_train_loader,test_loader,val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,lc_batch_size,config.INFO[\"num_workers\"])\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "torch.cuda.empty_cache()\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  use_projection_header=config.SSL[\"use_projection_header\"],\n",
    "                                  backbone_out_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = config.SSL[\"batch_size\"],\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"])\n",
    "\n",
    "# remove the max pooling layer and change the conv1 layer \n",
    "# for CIFAR10 dataset since the image is small(32*32)\n",
    "if config.DATA[\"dataset\"] == \"CIFAR10\":\n",
    "    ssl_model.backbone.remove_maxpool()\n",
    "    ssl_model.backbone.replace_conv1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 137\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 21.9 M | train\n",
      "-------------------------------------------------\n",
      "21.9 M    Trainable params\n",
      "0         Non-trainable params\n",
      "21.9 M    Total params\n",
      "87.739    Total estimated model params size (MB)\n",
      "120       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e657d0780884cd2b0fde4707a0826fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'save_every_n_epochs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 26\u001b[0m\n\u001b[1;32m      9\u001b[0m lc_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mLinearClassification(\n\u001b[1;32m     10\u001b[0m                  in_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mSSL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone_out_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     11\u001b[0m                  out_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124moutput_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m                  weight_decay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     17\u001b[0m                  n_epochs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     18\u001b[0m lc_model\u001b[38;5;241m.\u001b[39mset_backbone(ssl_model\u001b[38;5;241m.\u001b[39mbackbone)\n\u001b[1;32m     19\u001b[0m lc_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mtrain_lc(ssl_model \u001b[38;5;241m=\u001b[39m ssl_model, \n\u001b[1;32m     20\u001b[0m             ssl_ckpt_path \u001b[38;5;241m=\u001b[39m ssl_dir,\n\u001b[1;32m     21\u001b[0m             linear_model \u001b[38;5;241m=\u001b[39m lc_model,\n\u001b[1;32m     22\u001b[0m             train_loader \u001b[38;5;241m=\u001b[39m lc_train_loader,\n\u001b[1;32m     23\u001b[0m             val_loader \u001b[38;5;241m=\u001b[39m val_loader,\n\u001b[1;32m     24\u001b[0m             test_loader \u001b[38;5;241m=\u001b[39m test_loader,\n\u001b[1;32m     25\u001b[0m             max_epochs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m---> 26\u001b[0m             every_n_epochs \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_every_n_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m,\n\u001b[1;32m     27\u001b[0m             checkpoint_path \u001b[38;5;241m=\u001b[39m lc_dir,\n\u001b[1;32m     28\u001b[0m             mode \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtraining_mode\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'save_every_n_epochs'"
     ]
    }
   ],
   "source": [
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "ssl_model.backbone.remove_projection_header()\n",
    "if config.LC[\"lr_scale\"] == \"linear\":\n",
    "    lc_lr = config.LC[\"lr\"]*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "    lc_lr = config.LC[\"lr\"]*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "lc_model = lightning_models.LinearClassification(\n",
    "                 in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "lc_model.set_backbone(ssl_model.backbone)\n",
    "lc_model = lightning_models.train_lc(ssl_model = ssl_model, \n",
    "            ssl_ckpt_path = ssl_dir,\n",
    "            linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            val_loader = val_loader,\n",
    "            test_loader = test_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            checkpoint_path = lc_dir,\n",
    "            mode = config.LC[\"training_mode\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fd8969-7bdd-42cc-9e86-ac3a11f570a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "lc_model.load_from_customized_checkpoint(os.path.join(\"./simulations/lc\",\"last.ckpt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
