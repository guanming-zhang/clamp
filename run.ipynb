{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.5 (you have 1.4.23). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[KNN]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[KNN]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 4\n",
      "prefetch_factor = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = ddp\n",
      "if_profile = False\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 8\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "augmentation_package = albumentations\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 3\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "use_projection_head = True\n",
      "proj_dim = [4096]\n",
      "proj_out_dim = 512\n",
      "optimizer = LARS\n",
      "lr = 12.2\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine-restart\n",
      "grad_accumulation_steps = 1\n",
      "momentum = 0.0\n",
      "weight_decay = 0.0001\n",
      "lars_eta = 0.001\n",
      "loss_function = RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.0\n",
      "pot_pow = 1.0\n",
      "restart_epochs = 4\n",
      "rs = 3.0\n",
      "warmup_epochs = -1\n",
      "n_epochs = 8\n",
      "batch_size = 8\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "max_grad_norm = -1.0\n",
      "max_mem_size = 64\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = Adam\n",
      "use_batch_norm = False\n",
      "lr_sweep = [0.3, 0.1, 0.05]\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = -1.0\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 4\n",
      "save_every_n_epochs = 2\n",
      "batch_size = 1024\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "restart_training = False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5625\n",
      "625\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"]*config.SSL[\"grad_accumulation_steps\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,\n",
    "                                                                                num_workers = config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                standardized_to_imagenet=True,\n",
    "                                                                                augment_val_set = True,\n",
    "                                                                                prefetch_factor=config.INFO[\"prefetch_factor\"],\n",
    "                                                                                aug_pkg = config.DATA[\"augmentation_package\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))\n",
    "print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# check if the sub module is the same as needed\\nfor name, module in ssl_model.backbone.named_modules():\\n    print(name, \":\", module)\\n# check if the bachnorm is correctly converted to sync batchnorm\\n\\n\\nssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\\nfor name, module in ssl_model.backbone.named_modules():\\n    if isinstance(module, torch.nn.BatchNorm2d):\\n        print(f\"No BatchNorm2d NOT converted at: {name}\")\\n    elif isinstance(module, torch.nn.SyncBatchNorm):\\n        print(f\"Yes SyncBatchNorm converted at: {name}\")\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  loss_name= config.SSL[\"loss_function\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  scheduler_name = config.SSL[\"lr_scheduler\"],\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  restart_epochs = config.SSL[\"restart_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = ssl_batch_size,\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  max_mem_size = config.SSL[\"max_mem_size\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])\n",
    "'''\n",
    "# check if the sub module is the same as needed\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    print(name, \":\", module)\n",
    "# check if the bachnorm is correctly converted to sync batchnorm\n",
    "\n",
    "\n",
    "ssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        print(f\"No BatchNorm2d NOT converted at: {name}\")\n",
    "    elif isinstance(module, torch.nn.SyncBatchNorm):\n",
    "        print(f\"Yes SyncBatchNorm converted at: {name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/ssl exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 15.4 M | train\n",
      "-------------------------------------------------\n",
      "15.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "15.4 M    Total params\n",
      "61.471    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8638ac353b9b45bcba89b3ceddaa7032",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=8` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_grad_norm=config.SSL[\"max_grad_norm\"],\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/lc/lr_0.3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (43) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "117ffeb5b0e24a7ca9fee810b5f5f398",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "912a2d7dc6624e07a2d6df7520f4e19a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.4229600727558136\n",
      "     batch_test_acc5        0.8934462070465088\n",
      "     batch_test_loss         6.595719337463379\n",
      "        test_acc1           0.4229600727558136\n",
      "        test_acc5           0.8934462070465088\n",
      "        test_loss            6.595718860626221\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/lc/lr_0.1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38f83c4d87fe4ac99b12d41961e96095",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8c100350e3e4c518e9243d3f47d6d4c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.4235025942325592\n",
      "     batch_test_acc5        0.9110243320465088\n",
      "     batch_test_loss        2.4712228775024414\n",
      "        test_acc1           0.4235025942325592\n",
      "        test_acc5           0.9110243320465088\n",
      "        test_loss           2.4712228775024414\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/lc/lr_0.05 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25db1fb9e7a64d7a9c3b2a01a2081ec4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=4` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4974ef25e9e74ad6a987eee6649968d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.4281684160232544\n",
      "     batch_test_acc5        0.8980034589767456\n",
      "     batch_test_loss        1.6323636770248413\n",
      "        test_acc1           0.4281684160232544\n",
      "        test_acc5           0.8980034589767456\n",
      "        test_loss           1.6323637962341309\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "    ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = ssl_model.backbone.feature_dim,\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lc_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlc_dir\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lc_dir' is not defined"
     ]
    }
   ],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "                results = json.load(f)\n",
    "                best_lc_dir = results[\"best_model_dir\"] \n",
    "            lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= lc_model.linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transfer learning(freeze backbone)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mTL) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     tl_output_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m101\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m102\u001b[39m}\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = ssl_model.backbone.feature_dim,\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
