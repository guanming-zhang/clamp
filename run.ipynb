{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 4\n",
      "prefetch_factor = 8\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = auto\n",
      "if_profile = True\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 4\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 1\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "backbone_out_dim = 2048\n",
      "use_projection_head = True\n",
      "proj_dim = 2048\n",
      "proj_out_dim = 128\n",
      "optimizer = LARS\n",
      "lr = 0.8\n",
      "lr_scale = linear\n",
      "grad_accumulation_steps = 1\n",
      "momentum = 0.0\n",
      "weight_decay = 0.0001\n",
      "lars_eta = 0.001\n",
      "loss_function = EllipsoidPackingLoss\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.0\n",
      "pot_pow = 1.0\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 2\n",
      "batch_size = 128\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = SGD\n",
      "use_batch_norm = False\n",
      "lr = 0.2\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = 0.9\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 6\n",
      "save_every_n_epochs = 3\n",
      "batch_size = 256\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "restart_training = False\n",
      "lr_sweep = [0.1, 0.2, 0.3]\n",
      "\n",
      "lr overrided by lr_sweep!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "351\n",
      "39\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"]*config.SSL[\"grad_accumulation_steps\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                            validation=True,augment_val_set=True,\n",
    "                                                                            prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))\n",
    "print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  backbone_out_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = config.SSL[\"batch_size\"],\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory ./simulations/ssl/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/ssl exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 16.7 M | train\n",
      "-------------------------------------------------\n",
      "16.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.7 M    Total params\n",
      "66.712    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4812db093cff4e249c26338b6e112ffc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "150d7fc2d69842abae7d93f8155a14d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f47b406986b4932baa95120898ad3fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2cf6e550d7e49c4886a4cafef1629a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "FIT Profiler Report\n",
      "\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Action                                                                                                                                                              \t|  Mean duration (s)\t|  Num calls      \t|  Total time (s) \t|  Percentage %   \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  Total                                                                                                                                                               \t|  -              \t|  35315          \t|  123.25         \t|  100 %          \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "|  run_training_epoch                                                                                                                                                  \t|  60.936         \t|  2              \t|  121.87         \t|  98.879         \t|\n",
      "|  run_training_batch                                                                                                                                                  \t|  0.16138        \t|  702            \t|  113.29         \t|  91.917         \t|\n",
      "|  [LightningModule]CLAP.optimizer_step                                                                                                                                \t|  0.1612         \t|  702            \t|  113.16         \t|  91.81          \t|\n",
      "|  [Strategy]SingleDeviceStrategy.training_step                                                                                                                        \t|  0.051174       \t|  702            \t|  35.924         \t|  29.147         \t|\n",
      "|  [_EvaluationLoop].val_next                                                                                                                                          \t|  0.078309       \t|  80             \t|  6.2647         \t|  5.0828         \t|\n",
      "|  [Strategy]SingleDeviceStrategy.backward                                                                                                                             \t|  0.0053514      \t|  702            \t|  3.7567         \t|  3.0479         \t|\n",
      "|  [_TrainingEpochLoop].train_dataloader_next                                                                                                                          \t|  0.0010473      \t|  702            \t|  0.73521        \t|  0.5965         \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_end                                                                                                                        \t|  0.00098429     \t|  702            \t|  0.69097        \t|  0.56061        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.validation_step                                                                                                                      \t|  0.0071266      \t|  80             \t|  0.57013        \t|  0.46256        \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end            \t|  0.13012        \t|  2              \t|  0.26023        \t|  0.21113        \t|\n",
      "|  [Strategy]SingleDeviceStrategy.batch_to_device                                                                                                                      \t|  0.00030618     \t|  782            \t|  0.23944        \t|  0.19426        \t|\n",
      "|  [LightningModule]CLAP.optimizer_zero_grad                                                                                                                           \t|  0.00032195     \t|  702            \t|  0.22601        \t|  0.18337        \t|\n",
      "|  [LightningModule]CLAP.transfer_batch_to_device                                                                                                                      \t|  0.0002796      \t|  782            \t|  0.21865        \t|  0.1774         \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_end       \t|  0.073905       \t|  2              \t|  0.14781        \t|  0.11992        \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_end                                                                                                                   \t|  0.00046834     \t|  80             \t|  0.037467       \t|  0.030398       \t|\n",
      "|  [LightningModule]CLAP.configure_gradient_clipping                                                                                                                   \t|  3.1084e-05     \t|  702            \t|  0.021821       \t|  0.017704       \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end       \t|  1.5265e-05     \t|  702            \t|  0.010716       \t|  0.0086942      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_start                                                                                                                       \t|  0.0031597      \t|  3              \t|  0.0094792      \t|  0.0076908      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_start                                                                                                                            \t|  0.0065476      \t|  1              \t|  0.0065476      \t|  0.0053123      \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_start                                                                                                                     \t|  0.0046078      \t|  1              \t|  0.0046078      \t|  0.0037384      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_end                                                                                                                         \t|  0.001184       \t|  3              \t|  0.0035521      \t|  0.0028819      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_start                                                                                                                  \t|  4.5331e-06     \t|  702            \t|  0.0031822      \t|  0.0025819      \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_batch_start                                                                                                                 \t|  3.3775e-05     \t|  80             \t|  0.002702       \t|  0.0021922      \t|\n",
      "|  [LightningModule]CLAP.on_train_epoch_end                                                                                                                            \t|  0.0012843      \t|  2              \t|  0.0025685      \t|  0.0020839      \t|\n",
      "|  [Callback]LearningRateMonitor.on_after_backward                                                                                                                     \t|  2.8981e-06     \t|  702            \t|  0.0020345      \t|  0.0016506      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_end            \t|  2.6675e-06     \t|  702            \t|  0.0018726      \t|  0.0015193      \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_end                                                                                                                           \t|  2.5425e-06     \t|  702            \t|  0.0017848      \t|  0.0014481      \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_start                                                                                                                      \t|  0.00084772     \t|  2              \t|  0.0016954      \t|  0.0013756      \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_batch_end                                                                                                                    \t|  2.3739e-06     \t|  702            \t|  0.0016665      \t|  0.0013521      \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_optimizer_step                                                                                                              \t|  2.2906e-06     \t|  702            \t|  0.001608       \t|  0.0013046      \t|\n",
      "|  [Callback]ModelSummary.on_fit_start                                                                                                                                 \t|  0.0012149      \t|  1              \t|  0.0012149      \t|  0.00098567     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_zero_grad                                                                                                                   \t|  1.6407e-06     \t|  702            \t|  0.0011518      \t|  0.00093447     \t|\n",
      "|  [Callback]LearningRateMonitor.on_before_backward                                                                                                                    \t|  1.5014e-06     \t|  702            \t|  0.001054       \t|  0.00085515     \t|\n",
      "|  [LightningModule]CLAP.configure_optimizers                                                                                                                          \t|  0.00091136     \t|  1              \t|  0.00091136     \t|  0.00073942     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_start                                                                                                                  \t|  0.00041028     \t|  2              \t|  0.00082056     \t|  0.00066575     \t|\n",
      "|  [LightningModule]CLAP.on_before_batch_transfer                                                                                                                      \t|  1.0169e-06     \t|  782            \t|  0.0007952      \t|  0.00064517     \t|\n",
      "|  [LightningModule]CLAP.lr_scheduler_step                                                                                                                             \t|  0.00036905     \t|  2              \t|  0.0007381      \t|  0.00059884     \t|\n",
      "|  [LightningModule]CLAP.on_validation_model_zero_grad                                                                                                                 \t|  0.00035346     \t|  2              \t|  0.00070691     \t|  0.00057354     \t|\n",
      "|  [LightningModule]CLAP.on_before_zero_grad                                                                                                                           \t|  9.8331e-07     \t|  702            \t|  0.00069028     \t|  0.00056005     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_batch_start                                                                                                                      \t|  9.826e-07      \t|  702            \t|  0.00068978     \t|  0.00055964     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward             \t|  9.5839e-07     \t|  702            \t|  0.00067279     \t|  0.00054586     \t|\n",
      "|  [LightningModule]CLAP.on_before_optimizer_step                                                                                                                      \t|  9.581e-07      \t|  702            \t|  0.00067259     \t|  0.00054569     \t|\n",
      "|  [Callback]TQDMProgressBar.on_after_backward                                                                                                                         \t|  9.2022e-07     \t|  702            \t|  0.000646       \t|  0.00052412     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step      \t|  9.1463e-07     \t|  702            \t|  0.00064207     \t|  0.00052093     \t|\n",
      "|  [LightningModule]CLAP.on_after_backward                                                                                                                             \t|  8.8886e-07     \t|  702            \t|  0.00062398     \t|  0.00050626     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_optimizer_step                                                                                                                  \t|  8.8499e-07     \t|  702            \t|  0.00062126     \t|  0.00050405     \t|\n",
      "|  [LightningModule]CLAP.on_after_batch_transfer                                                                                                                       \t|  7.9142e-07     \t|  782            \t|  0.00061889     \t|  0.00050213     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_after_backward        \t|  8.5831e-07     \t|  702            \t|  0.00060253     \t|  0.00048885     \t|\n",
      "|  [LightningModule]CLAP.on_train_batch_end                                                                                                                            \t|  8.4184e-07     \t|  702            \t|  0.00059098     \t|  0.00047948     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_optimizer_step \t|  7.6739e-07     \t|  702            \t|  0.00053871     \t|  0.00043707     \t|\n",
      "|  [Callback]ModelSummary.on_before_optimizer_step                                                                                                                     \t|  7.5907e-07     \t|  702            \t|  0.00053287     \t|  0.00043233     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_zero_grad                                                                                                                       \t|  7.4505e-07     \t|  702            \t|  0.00052303     \t|  0.00042435     \t|\n",
      "|  [LightningModule]CLAP.on_validation_model_eval                                                                                                                      \t|  0.00016847     \t|  3              \t|  0.00050542     \t|  0.00041007     \t|\n",
      "|  [Callback]ModelSummary.on_after_backward                                                                                                                            \t|  6.9691e-07     \t|  702            \t|  0.00048923     \t|  0.00039693     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_batch_start                                                                                                                 \t|  6.883e-07      \t|  702            \t|  0.00048319     \t|  0.00039203     \t|\n",
      "|  [LightningModule]CLAP.on_train_batch_start                                                                                                                          \t|  6.8256e-07     \t|  702            \t|  0.00047916     \t|  0.00038876     \t|\n",
      "|  [LightningModule]CLAP.on_before_backward                                                                                                                            \t|  6.6178e-07     \t|  702            \t|  0.00046457     \t|  0.00037692     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward            \t|  5.9548e-07     \t|  702            \t|  0.00041803     \t|  0.00033916     \t|\n",
      "|  [Callback]ModelSummary.on_train_batch_start                                                                                                                         \t|  5.683e-07      \t|  702            \t|  0.00039895     \t|  0.00032368     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start     \t|  5.1793e-07     \t|  702            \t|  0.00036358     \t|  0.00029499     \t|\n",
      "|  [Callback]TQDMProgressBar.on_before_backward                                                                                                                        \t|  4.9631e-07     \t|  702            \t|  0.00034841     \t|  0.00028268     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad      \t|  4.8315e-07     \t|  702            \t|  0.00033917     \t|  0.00027518     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_batch_start          \t|  4.8056e-07     \t|  702            \t|  0.00033736     \t|  0.00027371     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_backward       \t|  4.3675e-07     \t|  702            \t|  0.0003066      \t|  0.00024875     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_before_zero_grad           \t|  4.2051e-07     \t|  702            \t|  0.00029519     \t|  0.0002395      \t|\n",
      "|  [Callback]ModelSummary.on_before_zero_grad                                                                                                                          \t|  4.1978e-07     \t|  702            \t|  0.00029468     \t|  0.00023909     \t|\n",
      "|  [Callback]ModelSummary.on_before_backward                                                                                                                           \t|  4.1414e-07     \t|  702            \t|  0.00029073     \t|  0.00023588     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_end                                                                                                                              \t|  0.00024718     \t|  1              \t|  0.00024718     \t|  0.00020055     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                    \t|  0.00023716     \t|  1              \t|  0.00023716     \t|  0.00019242     \t|\n",
      "|  [Callback]TQDMProgressBar.on_train_epoch_end                                                                                                                        \t|  0.0001061      \t|  2              \t|  0.00021221     \t|  0.00017217     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_start                                                                                                             \t|  1.7911e-06     \t|  80             \t|  0.00014329     \t|  0.00011625     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_batch_end                                                                                                               \t|  1.7296e-06     \t|  80             \t|  0.00013837     \t|  0.00011226     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_end                                                                                                                      \t|  1.4709e-06     \t|  80             \t|  0.00011767     \t|  9.5469e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_start                                                                                                                        \t|  7.7315e-05     \t|  1              \t|  7.7315e-05     \t|  6.2728e-05     \t|\n",
      "|  [LightningModule]CLAP.on_validation_batch_start                                                                                                                     \t|  8.8165e-07     \t|  80             \t|  7.0532e-05     \t|  5.7225e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end        \t|  2.346e-05      \t|  3              \t|  7.0381e-05     \t|  5.7102e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start     \t|  8.684e-07      \t|  80             \t|  6.9472e-05     \t|  5.6365e-05     \t|\n",
      "|  [LightningModule]CLAP.on_validation_batch_end                                                                                                                       \t|  8.387e-07      \t|  80             \t|  6.7096e-05     \t|  5.4437e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_start\t|  7.0721e-07     \t|  80             \t|  5.6577e-05     \t|  4.5903e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.setup                         \t|  5.1626e-05     \t|  1              \t|  5.1626e-05     \t|  4.1886e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end  \t|  6.4151e-07     \t|  80             \t|  5.1321e-05     \t|  4.1638e-05     \t|\n",
      "|  [Callback]ModelSummary.on_validation_batch_start                                                                                                                    \t|  6.1293e-07     \t|  80             \t|  4.9034e-05     \t|  3.9783e-05     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_batch_end       \t|  5.0303e-07     \t|  80             \t|  4.0242e-05     \t|  3.265e-05      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_end             \t|  5.4307e-06     \t|  3              \t|  1.6292e-05     \t|  1.3218e-05     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_end                                                                                                               \t|  4.0107e-06     \t|  3              \t|  1.2032e-05     \t|  9.762e-06      \t|\n",
      "|  [Callback]TQDMProgressBar.on_sanity_check_end                                                                                                                       \t|  8.366e-06      \t|  1              \t|  8.366e-06      \t|  6.7876e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_end                                                                                                                     \t|  2.391e-06      \t|  3              \t|  7.173e-06      \t|  5.8197e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_start                                                                                                                   \t|  2.3277e-06     \t|  3              \t|  6.983e-06      \t|  5.6655e-06     \t|\n",
      "|  [Callback]ModelSummary.on_validation_end                                                                                                                            \t|  2.2343e-06     \t|  3              \t|  6.703e-06      \t|  5.4384e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.setup                                                                                                                                 \t|  6.493e-06      \t|  1              \t|  6.493e-06      \t|  5.268e-06      \t|\n",
      "|  [Callback]ModelSummary.on_validation_start                                                                                                                          \t|  2.0107e-06     \t|  3              \t|  6.032e-06      \t|  4.894e-06      \t|\n",
      "|  [Callback]TQDMProgressBar.setup                                                                                                                                     \t|  5.791e-06      \t|  1              \t|  5.791e-06      \t|  4.6984e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_save_checkpoint                                                                                                                    \t|  1.7633e-06     \t|  3              \t|  5.29e-06       \t|  4.2919e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_start                                                                                                                  \t|  1.6727e-06     \t|  3              \t|  5.018e-06      \t|  4.0713e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_validation_epoch_start                                                                                                             \t|  1.6233e-06     \t|  3              \t|  4.87e-06       \t|  3.9512e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_start                                                                                                                         \t|  2.4145e-06     \t|  2              \t|  4.829e-06      \t|  3.9179e-06     \t|\n",
      "|  [LightningModule]CLAP.on_validation_epoch_start                                                                                                                     \t|  1.5697e-06     \t|  3              \t|  4.709e-06      \t|  3.8206e-06     \t|\n",
      "|  [Callback]ModelSummary.on_train_start                                                                                                                               \t|  4.188e-06      \t|  1              \t|  4.188e-06      \t|  3.3979e-06     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_validation_end                                                                                                                    \t|  1.379e-06      \t|  3              \t|  4.137e-06      \t|  3.3565e-06     \t|\n",
      "|  [LightningModule]CLAP.configure_callbacks                                                                                                                           \t|  3.987e-06      \t|  1              \t|  3.987e-06      \t|  3.2348e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_start                                                                                                                          \t|  3.838e-06      \t|  1              \t|  3.838e-06      \t|  3.1139e-06     \t|\n",
      "|  [LightningModule]CLAP.on_validation_end                                                                                                                             \t|  1.2787e-06     \t|  3              \t|  3.836e-06      \t|  3.1123e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start           \t|  3.417e-06      \t|  1              \t|  3.417e-06      \t|  2.7723e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_save_checkpoint                                                                                                                        \t|  1.0353e-06     \t|  3              \t|  3.106e-06      \t|  2.52e-06       \t|\n",
      "|  [Callback]LearningRateMonitor.teardown                                                                                                                              \t|  2.985e-06      \t|  1              \t|  2.985e-06      \t|  2.4218e-06     \t|\n",
      "|  [LightningModule]CLAP.on_fit_start                                                                                                                                  \t|  2.975e-06      \t|  1              \t|  2.975e-06      \t|  2.4137e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_end                                                                                                                   \t|  2.675e-06      \t|  1              \t|  2.675e-06      \t|  2.1703e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_epoch_end                                                                                                                    \t|  1.2125e-06     \t|  2              \t|  2.425e-06      \t|  1.9675e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_fit_end                                                                                                                            \t|  2.334e-06      \t|  1              \t|  2.334e-06      \t|  1.8936e-06     \t|\n",
      "|  [LightningModule]CLAP.on_validation_epoch_end                                                                                                                       \t|  7.7133e-07     \t|  3              \t|  2.314e-06      \t|  1.8774e-06     \t|\n",
      "|  [LightningModule]CLAP.on_train_epoch_start                                                                                                                          \t|  1.1015e-06     \t|  2              \t|  2.203e-06      \t|  1.7874e-06     \t|\n",
      "|  [LightningModule]CLAP.on_validation_start                                                                                                                           \t|  6.6133e-07     \t|  3              \t|  1.984e-06      \t|  1.6097e-06     \t|\n",
      "|  [Callback]ModelSummary.on_save_checkpoint                                                                                                                           \t|  6.4467e-07     \t|  3              \t|  1.934e-06      \t|  1.5691e-06     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_start                                                                                                                        \t|  1.894e-06      \t|  1              \t|  1.894e-06      \t|  1.5367e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start           \t|  5.8767e-07     \t|  3              \t|  1.763e-06      \t|  1.4304e-06     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_end                                                                                                                   \t|  5.4767e-07     \t|  3              \t|  1.643e-06      \t|  1.333e-06      \t|\n",
      "|  [Callback]ModelSummary.on_train_epoch_end                                                                                                                           \t|  7.82e-07       \t|  2              \t|  1.564e-06      \t|  1.2689e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_start      \t|  5.2067e-07     \t|  3              \t|  1.562e-06      \t|  1.2673e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_sanity_check_start                                                                                                                 \t|  1.533e-06      \t|  1              \t|  1.533e-06      \t|  1.2438e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end  \t|  5.0733e-07     \t|  3              \t|  1.522e-06      \t|  1.2348e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint       \t|  5.01e-07       \t|  3              \t|  1.503e-06      \t|  1.2194e-06     \t|\n",
      "|  [LightningModule]CLAP.setup                                                                                                                                         \t|  1.503e-06      \t|  1              \t|  1.503e-06      \t|  1.2194e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_start                \t|  1.413e-06      \t|  1              \t|  1.413e-06      \t|  1.1464e-06     \t|\n",
      "|  [Callback]LearningRateMonitor.on_train_end                                                                                                                          \t|  1.403e-06      \t|  1              \t|  1.403e-06      \t|  1.1383e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start     \t|  6.56e-07       \t|  2              \t|  1.312e-06      \t|  1.0645e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_save_checkpoint            \t|  4.2733e-07     \t|  3              \t|  1.282e-06      \t|  1.0401e-06     \t|\n",
      "|  [LightningModule]CLAP.on_save_checkpoint                                                                                                                            \t|  4.21e-07       \t|  3              \t|  1.263e-06      \t|  1.0247e-06     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start     \t|  3.7667e-07     \t|  3              \t|  1.13e-06       \t|  9.1681e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_start\t|  3.74e-07       \t|  3              \t|  1.122e-06      \t|  9.1032e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_validation_epoch_start                                                                                                                 \t|  3.6433e-07     \t|  3              \t|  1.093e-06      \t|  8.8679e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_validation_epoch_end       \t|  3.64e-07       \t|  3              \t|  1.092e-06      \t|  8.8598e-07     \t|\n",
      "|  [LightningModule]CLAP.on_train_start                                                                                                                                \t|  1.052e-06      \t|  1              \t|  1.052e-06      \t|  8.5352e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_start                                                                                                                    \t|  3.5067e-07     \t|  3              \t|  1.052e-06      \t|  8.5352e-07     \t|\n",
      "|  [Callback]ModelSummary.on_validation_epoch_end                                                                                                                      \t|  3.5067e-07     \t|  3              \t|  1.052e-06      \t|  8.5352e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_epoch_start          \t|  5.055e-07      \t|  2              \t|  1.011e-06      \t|  8.2026e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start             \t|  9.82e-07       \t|  1              \t|  9.82e-07       \t|  7.9673e-07     \t|\n",
      "|  [LightningModule]CLAP.on_train_end                                                                                                                                  \t|  9.32e-07       \t|  1              \t|  9.32e-07       \t|  7.5616e-07     \t|\n",
      "|  [Callback]ModelSummary.on_train_end                                                                                                                                 \t|  9.22e-07       \t|  1              \t|  9.22e-07       \t|  7.4805e-07     \t|\n",
      "|  [LightningModule]CLAP.teardown                                                                                                                                      \t|  9.12e-07       \t|  1              \t|  9.12e-07       \t|  7.3993e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_start                                                                                                                       \t|  8.92e-07       \t|  1              \t|  8.92e-07       \t|  7.2371e-07     \t|\n",
      "|  [LightningModule]CLAP.on_fit_end                                                                                                                                    \t|  8.22e-07       \t|  1              \t|  8.22e-07       \t|  6.6691e-07     \t|\n",
      "|  [Callback]ModelSummary.on_sanity_check_end                                                                                                                          \t|  7.81e-07       \t|  1              \t|  7.81e-07       \t|  6.3365e-07     \t|\n",
      "|  [Strategy]SingleDeviceStrategy.on_train_end                                                                                                                         \t|  7.21e-07       \t|  1              \t|  7.21e-07       \t|  5.8497e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.teardown                                                                                                                                  \t|  6.91e-07       \t|  1              \t|  6.91e-07       \t|  5.6063e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                 \t|  6.62e-07       \t|  1              \t|  6.62e-07       \t|  5.371e-07      \t|\n",
      "|  [Callback]ModelSummary.teardown                                                                                                                                     \t|  6.52e-07       \t|  1              \t|  6.52e-07       \t|  5.2899e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.teardown                      \t|  6.51e-07       \t|  1              \t|  6.51e-07       \t|  5.2818e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end      \t|  5.92e-07       \t|  1              \t|  5.92e-07       \t|  4.8031e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_end                                                                                                                                \t|  5.81e-07       \t|  1              \t|  5.81e-07       \t|  4.7139e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end             \t|  5.81e-07       \t|  1              \t|  5.81e-07       \t|  4.7138e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_start                  \t|  5.71e-07       \t|  1              \t|  5.71e-07       \t|  4.6327e-07     \t|\n",
      "|  [Callback]TQDMProgressBar.on_fit_start                                                                                                                              \t|  5.62e-07       \t|  1              \t|  5.62e-07       \t|  4.5597e-07     \t|\n",
      "|  [Callback]ModelSummary.setup                                                                                                                                        \t|  5.61e-07       \t|  1              \t|  5.61e-07       \t|  4.5516e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start         \t|  5.11e-07       \t|  1              \t|  5.11e-07       \t|  4.1459e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_end           \t|  4.71e-07       \t|  1              \t|  4.71e-07       \t|  3.8214e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_train_end                  \t|  4.71e-07       \t|  1              \t|  4.71e-07       \t|  3.8214e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_sanity_check_start    \t|  4.6e-07        \t|  1              \t|  4.6e-07        \t|  3.7321e-07     \t|\n",
      "|  [Callback]ModelSummary.on_fit_end                                                                                                                                   \t|  4.51e-07       \t|  1              \t|  4.51e-07       \t|  3.6591e-07     \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': 'val_acc', 'mode': 'max', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end               \t|  4.41e-07       \t|  1              \t|  4.41e-07       \t|  3.578e-07      \t|\n",
      "|  [Callback]ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}.on_fit_end                    \t|  4.1e-07        \t|  1              \t|  4.1e-07        \t|  3.3265e-07     \t|\n",
      "--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b163edae-f73e-4982-a53d-89e00a2d031c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulation_imagenet/ssl'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssl_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.1/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.2/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.3/best_val.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "    ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulation_imagenet/lc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.1/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.2/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.3/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.1/best_val.ckpt, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory ./simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.2/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 27.7 M | train\n",
      "1 | linear_net | BnLinearNet | 2.1 M  | train\n",
      "---------------------------------------------------\n",
      "29.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 M    Total params\n",
      "119.030   Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ab7adb337646ae9e7acbcb2fa37553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f164359336b471eb21ca5c62e8a70da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "     batch_test_acc1       0.0013404289493337274\n",
      "     batch_test_acc5        0.00616197194904089\n",
      "     batch_test_loss         8.386237144470215\n",
      "        test_acc1          0.0013404289493337274\n",
      "        test_acc5           0.00616197194904089\n",
      "        test_loss            8.386237144470215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 27.7 M | train\n",
      "1 | linear_net | BnLinearNet | 2.1 M  | train\n",
      "---------------------------------------------------\n",
      "29.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 M    Total params\n",
      "119.030   Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb217f39bf3e4dda931b17222be0b107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2541fb439a19467fb2a7db0040b65332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "     batch_test_acc1       0.001260403310880065\n",
      "     batch_test_acc5       0.004921575076878071\n",
      "     batch_test_loss         9.744197845458984\n",
      "        test_acc1          0.001260403310880065\n",
      "        test_acc5          0.004921575076878071\n",
      "        test_loss            9.744195938110352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "                results = json.load(f)\n",
    "                best_lc_dir = results[\"best_model_dir\"] \n",
    "            lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= lc_model.linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transfer learning(freeze backbone)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mTL) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     tl_output_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m101\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m102\u001b[39m}\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
