{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[KNN]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[KNN]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 4\n",
      "prefetch_factor = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = auto\n",
      "if_profile = False\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 16\n",
      "n_trans = 1\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "augmentation_package = albumentations\n",
      "crop_size = [32]\n",
      "crop_min_scale = [0.08]\n",
      "crop_max_scale = [1.0]\n",
      "hflip_prob = [0.5]\n",
      "blur_kernel_size = [3]\n",
      "blur_prob = [0.5]\n",
      "grayscale_prob = [0.2]\n",
      "jitter_brightness = [0.8]\n",
      "jitter_contrast = [0.8]\n",
      "jitter_saturation = [0.8]\n",
      "jitter_hue = [0.2]\n",
      "jitter_prob = [0.8]\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "use_projection_head = True\n",
      "proj_dim = [2048]\n",
      "proj_out_dim = 256\n",
      "optimizer = LARS\n",
      "lr = 0.1\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine-warmup\n",
      "momentum = 0.9\n",
      "weight_decay = 1e-06\n",
      "scale_weight_decay = True\n",
      "lars_eta = 0.001\n",
      "loss_function = RepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.0\n",
      "pot_pow = 2.0\n",
      "restart_epochs = -1\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 2\n",
      "batch_size = 8\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "exclude_bn_bias_from_weight_decay = True\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = Adam\n",
      "use_batch_norm = False\n",
      "lr_sweep = [0.3, 0.1, 0.05]\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = -1.0\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 2\n",
      "save_every_n_epochs = 5\n",
      "batch_size = 16\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "restart_training = False\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5937\n",
      "312\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfoAAAHVCAYAAAAZ7zmqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAgkklEQVR4nO3dbYym51Uf8GvqWWVWnlVmldl4N96NvbGX2k5iYjc2tVGgSRVSu1BKJPohRQRKkWhp1ZRKUKhoQX0RUPohqB9aJSLhRbxKQAnEaQwB2Y0DTmQTO8mGGGcdO2Ztdq2d1Y67E+2Y6YdKVdM+5+9nbs+ud8/+fh+vv6/7vp6XnZNHuk/OwtbW1tYAAFr6Ky/3AQCA80ehB4DGFHoAaEyhB4DGFHoAaEyhB4DGFHoAaEyhB4DGFl/uA1y6fr+OHvjmMvqnX79RZr9QrJ+e80QXq6tC9sDddfa6KjhxXb1p39vr7Ie+o86+4evrjEmWFhbqbML1LvV/B3A+zPP/eecXPQA0ptADQGMKPQA0ptADQGMKPQA0ptADQGML88+jr1tlxvjakP1ksf6O+W57SfqlMjn1nr9fZt/53tnrv/NSj3MRS613P1qsvzXsuemNIfyeb6mzd95aZ4euDhetfO+EPb3sD+11K2Fflf3xSzgLdKW9DgAucwo9ADSm0ANAYwo9ADSm0ANAYwo9ADS2Q+11yduK9TD9rbV31dEDvzxz+bvDYLUPvrTDXNSq1rvvDntS691td9TZ3kNh47E6OnW0uN7tYT7b4W+rs/fXrZmXmtXQXndD2Fc1Qf5Z2PP+eQ4EDWmvA4DLnEIPAI0p9ADQmEIPAI0p9ADQ2AV46v67ivUPhD1/GbLTIdsM2b6QXSyq58k/WO748fCx/NhLOco2XRGy8Pz5eD5k1VP34eH58Y9Cth6y8GB99Eyxvhj2rIbsX8z7z/ESsBCeuk++o1hP79snQmYYDp156h4ALnMKPQA0ptADQGMKPQA0ptADQGMKPQA0to32uvdNvEXVJHVT2PN4yJ4LWWrWqsadXB/2XCxOhOyWMvnehafLbKeHgFwXstRe90TI0qdZuTpkYZTM2B+ytZA9XKz/UdiTXtfc/xwvAVPb64D5aa8DgMucQg8AjSn0ANCYQg8AjSn0ANCYQg8AjW2jvS7NBbsyZNUcr9SQ9eshezJkabLdu4v1nwh7LgX1+f/ivT9cZu96T33FPyzW0/SwNK0tzRR8NmQ7LX1Lvz1kb5hwrw+F7FMhW9deB2yD9joAuMwp9ADQmEIPAI0p9ADQmEIPAI0p9ADQWOqK+n/8lx2+9e0heyhkqVkrqa7538Oed0y81077tZB9rExe/f31rv9wrM7u//Ds9Sceq/d8so5iO9mFlKbGVVPoxsitd3e/q9izVu/5SPH+ApwPftEDQGMKPQA0ptADQGMKPQA0ptADQGMKPQA0to3pdRdyEtWdIbt54jWvKdZfN/FeN0w8xwdCdk+xnqb5BaEd7tSJOtu7VgQb9Z4P/8s6uyecY/9ynT2xXlyv3jKeDlmaXvfWkH13yN7500XwtrBpOXy/j3w8bLy0mF4H55/pdQBwmVPoAaAxhR4AGlPoAaAxhR4AGtvGUJsL6dmQpeej/94OnyM8mj4+H7L3huz9Idv+wJ4P/1id/cLP19lyeNr92945e/3uMIdo/2qdLYWn7p8pnqwfY4y7Dsxe/+dL9Z4bQ2fA0eN19kQdjZMhG9WAmvD+jkMP1NmRdDOA7fOLHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoLGLdKhN8vaQfXTC9c6G7L6Q/aeQ3TvhHLWPhm69d7xnR281xhjjqmL9rrBnf8ieCFnorht/o1j/gTvqPQu3hgumZtIH6+jnP1FnVVfhHYfrPXvvDuf4z3P+c7wEGGoD55+hNgBwmVPoAaAxhR4AGlPoAaAxhR4AGlPoAaCxuafXbYVBbgthYtg4tI3TzCW1rr0pZLcU62nM2D0hezxk0/zwt85e/4nf3vFbRdXswA9OvN7rQ7YWsuortxTa3b4/DQD8ZxNuNsZYDve7v1g/dqzec1s18W6MEQYEAkziFz0ANKbQA0BjCj0ANKbQA0BjCj0ANKbQA0BjOzO9bi1sO1Os73jb3cVj6+E6+zt/u85+5/jOn+Vi97vvqrP1R2evLxbrY4xxbbjXrWHq3dYTdfaD4XOpmj2rZs4xxvj2A3V295+bXgfMz/Q6ALjMKfQA0JhCDwCNKfQA0JhCDwCNKfQA0Njc0+tGmFD3Fw/U2acenL1+7eF6z03vnu9IL6cvhtf8rq+vsz/e+aNc0t4XJvO96cbZ6wfeWO9ZClPjUhPKPaGF7n1h3+li/TNhz1tDBrDT/KIHgMYUegBoTKEHgMYUegBoTKEHgMYUegBobP72uqN1VLXQjTHG0d8obvwN9Z6b3hbOcZFMvfu331dnWujm91vrIfvk7PXXh+t9e8ju2F1nR1fr7PTJcNHCCyFLrXzfuf1bAUR+0QNAYwo9ADSm0ANAYwo9ADSm0ANAY3M/dX9quc5W99bZje+cvf5NYajNxfJk/Viro6OhC4Hz67Mh+3zIbguf2WcmPFk/1a+E7Jcv2CmAy4Vf9ADQmEIPAI0p9ADQmEIPAI0p9ADQmEIPAI3N3V73U2GIS3J4afZ6mIMzbv+5EL572jkmWamjP3qkzt50c519enPyaZhDGiZzNAyTuXfHTwJwcfCLHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoLGFra2trbn+w4WFMrsy7Lu+WL8x7Fk+UGff+511dvtPhIteQKfuq7Mbv7HOnt35o1x2rgjZh1fr7AfC9Lo0LW+nzfnP8ZKQ/mYAO2Oevxl+0QNAYwo9ADSm0ANAYwo9ADSm0ANAYwo9ADS2I+11F9LVIfuZfxPCjdnLb7693vLad85zou158Mfq7Ot+fOfvt5P+6/fU2bVvrLN7H6izn/616eeZ5X/+uzrbHVozH/yuOvu6j00+zrZprwO2Q3sdAFzmFHoAaEyhB4DGFHoAaEyhB4DGFHoAaGzu9rqVia0ym8X685OulqUpelPu983LdfbmMH7vttCy9+bb6uwj989e/6lfrfd8dr3Opnr2d2evv/rutOtrQ/alkK296Hl2zp0h+1zI1rZ9p3//3jr7j+8Jd9Jed9F7RchWJl6z6P590ayyFLIbQnZkwr3GGONDxfrpiddjftrrAOAyp9ADQGMKPQA0ptADQGMKPQA0NvdT92OEJ2jX6uiLxcPM/+pH6z2/cgGHiEyVnvD/6yH7x+HJ9XcWT7tfPH42ZK8J2Z+HLL2T1dP66Qn5JD11vxiy+0L2wWlHKXnqfoqrQrYSsvR0+koRHtgb9oROnfgVS8K+xSJbDI/qH1yrswPH6yw1+Px8sf7xsIevlr7Db1its9874al7ALisKfQA0JhCDwCNKfQA0JhCDwCNKfQA0NjUho+vtlJHrys6mn759+s9y99aZ+//7blO9P+pWhfuCu0w3/K2Orv2lnCz0Nqy+sawb8elj/etIbu1WP/TsCdlV4esGns0Rv3FuibsSQN0pn7d0/1+qFj/SNjz6YnnuLylYTKr4aNdCdmekC0X2Wroyata8sYYYzn8rVncFbKwb3dxv9RetxJa6FZP1dlauOaeOmJOdxyosxteYt3wix4AGlPoAaAxhR4AGlPoAaAxhR4AGlPoAaCxnWmv22Hv+28hu3DHGGPcHrKbQvaLIUvtZDvt9SG7OWRfLNZ/feI59ofs74asavNL7XqvetHTzJba8u4J2VeK9ZNhz0X5z+7SFv5ZLaYRdemj2F3cKu2ZcL0x8hmrFroxxliqsnSOMH1v7Kujzafq7Fy4JF+t+gt17ZF6z8FDL+2eftEDQGMKPQA0ptADQGMKPQA0ptADQGMKPQA0dhn1+RRj9Ca1d42RJ5r9w5D965B9LGRTpHlf94fsyQn3Sj1MqRUxvcevLdafC3vCiK2xHrL0eaZJf5+ccI70XlF9a68Pf62OhMlfq2H621K4ZtW6thLa5FbCvfak6XWp9S6cscrSnqV0r9T9G9rrmN9KtR7+LOx5iX8y/KIHgMYUegBoTKEHgMYUegBoTKEHgMYUegBorFl73V8NWdXydkfY8zUhS/8bKU1Q+8GQPV2sp56X1MaVnA7ZK7e5PkZuk0vtaan17qpiPbXXpSx9nsmUiXhpz5UTz3Fp+WuhJSi1f+3bM3v94Gq952CYyLZvh9vrlkN72lK61/noqizOv1S8h2OMsRxGzaX3Y/NYnR3Seje3qsn3mcfqPS/1q+MXPQA0ptADQGMKPQA0ptADQGMKPQA01uyp+/QE/VuK9evDnr8M2YmQVU/PjzHGwyH7rmL9S2HPQyFLrg5Z9XR6+rrcHLLqvR9jjPCY8ni2WE9PtKfhNOn8qbNhivScbHh8vJG3HK6z9HR3NRimehp/jDy4Zjl8FEu7QlY9dZ/uFZ7+3x3OcS40z2yGp+QXi/PvCV+xdI4ROgr2hCfr31RkfzPcKo2YuiVk14bX9icnZ6//SrjehVb9Vbs/dDU8FrIfmuOeftEDQGMKPQA0ptADQGMKPQA0ptADQGMKPQA01qy97q6QpTa6yhdCdm/I3huyx0P29nycma4LWRpCk7KVYj21DabXlQbNXBGyqlUunT213qUBQF8JWfK3ivUnJ16vj1v21Vn6w1O1taWWvOXQHbkUsuXUXlftqbeM0F03doXzb6VhMqm9rti3kN7g0EJX/tMfY+wN2Y3FempaPRDa/O56dzjHkTp7pOo2/qV6T2q9e0XIbghZ8vli/cthT9E1ODe/6AGgMYUeABpT6AGgMYUeABpT6AGgMYUeABpr1l5XTV1LUlPDT4bsgxPu9WJOF+u3TtgzxvQ2tBeK9SsnnmNqq9nzxXr6nFPzU5oCWL3mqV4bss/t8L0uTm8IU8Y2U99VkaUtiyFcDGPS4jmKtrbUJrfrbLhesBBa6HalM1b3S6PhktSBmiYOFuuhE268IYyo23tb2BimIt5cnPGtn6j3PBwmw6W3Ph0xzac8VKyH4YDxY5mHX/QA0JhCDwCNKfQA0JhCDwCNKfQA0JhCDwCNNWuvq9qxxhjjT4r1Xwx7Pjj5JNPcVKynNrnXhSy1jK2EbEozR2qvm+rZYj2dL7UNJmk+1JR/Jum7GMZ2NXI4TK87F/qWNoqWsY3wsacsiW15RbaY7jW1rS31cU1seZt0vdQeGPZtFl/p9P6OMDlwrIXseMgKB/eHLLTXpebr1Mh7R2gdvGVt9vpj4RzFlrn5RQ8AjSn0ANCYQg8AjSn0ANCYQg8AjSn0ANDYNpozrgvZ4y/5IDvjB0P2YLGe+j/Oh38SsmoqW2oZmzoZ7rmQVVPqpragpWlz6RxVr1LqD0ptba8IWZLe4+qaqYXuqonnuLQshf6jpfDPbnfx1p0NH/t6agtLLXRh21IRVusvKn1tJ0zzi9nUM4Z7baVr7i3Ww1S+2Il4KmQT3o+VPfWWaprcGPkvXjrGUrjftcUNV8K/l7W1cLM5+EUPAI0p9ADQmEIPAI0p9ADQmEIPAI0p9ADQ2DaaMC6WFrrkgZf7AHN4KGRVq1Zqr6ta4cbI/TxfDFk1Le+RsGc1ZKmFLrXeVe/HF8Keh0MWRkpFO92COXXC3qXlRPj6pT88i1UY2o+WJw4E3BU+2uXiHLvOx8zPcI406W+zOMvuqVPjQrZQtdCNMZaL6XCb6U9Q+MzOhX3p+NX7mFoiD4bLPROy9DWIAweL7/HKgXrPUnjv5+EXPQA0ptADQGMKPQA0ptADQGMKPQA0dj6eHyVKnQFXF+uvD3vS48ZPT8yqp+vTo7xpmMw1IUtP5FdPp4fHr+MYivS0fupeeCFkUwbUpGdy+/iz43VWPlk/xlguBoKkoR97V+os/QtJ2UIV7PQAmpGfrF9P1yzex/T+7kovOlWElTpaLZ4YXwxf9eXUqBPOuBW2bVT3C+/hofC0++aJOktPyafzr00ZRPQSK7Vf9ADQmEIPAI0p9ADQmEIPAI0p9ADQmEIPAI1pr7uoVL0hqWXs2ZA9OTFL96vcFLJqSM4YY6yHrBpqk/ak1rsktQemfqSqV6Y6++VjLXxMqf2r+qu0nD7acL3FNKglXLJ0NmQT2+vi2KTw2s5N2DM5C/8MdhefzUa43tLucIyJlWlzwvyppfC6VlbqbOr38eXgFz0ANKbQA0BjCj0ANKbQA0BjCj0ANKbQA0BjC1tbW2kYEABwCfOLHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoLHFuf/Lo1+us82NkK3PXj8b7rU7ZIvL4V6bdXamOOPecL2VV9XZnqU6S86m96o4/9pz9Z4zT9fZsS/U2clwzY3ijEvhNVd7xhjj7PN1tl58P5Ll8Jkdel2d3XhT2HdNne0J34OV6p/QlfWey+R/Xy8sLLzcR4D25pk0f3n8xQGAy5RCDwCNKfQA0JhCDwCNKfQA0Nj8T91vhKej05Pk44X5T/N/rndFne0JT9ZPOceZ8LoW05P14RyL4W1NnQEpm2JXePJ7ecLT7unJ+vRE/gjZnvR0eiF9Lkvzf6Xnlz6zYn1xwvd+jOF/ewM7zV8VAGhMoQeAxhR6AGhMoQeAxhR6AGhMoQeAxubvRXrqS3W2EYaWVMphIGOMpavCvULbUmpPO7k2ez29A5vpXhPawv73xu1nqXNtOQxcScOBjqX2r5Mhq87xyjo7EIbQpH2V9BZO7a5L7aPpmueKD2d3askLF1zZG24GsH1+0QNAYwo9ADSm0ANAYwo9ADSm0ANAY9sYavPn065ytniaeSM9iR0ueC4MvDn5lTrbXJu9fqLeErsJTk4cXHMu3K964PrQNfWe5fD0/0p4In9/eG3VcKCl8JkdCJ0S+66usxHOv1S8j+upG2KtzhbD+eM8ofBZ735F2lhcboeHFwEEftEDQGMKPQA0ptADQGMKPQA0ptADQGMKPQA0to0RIKEl6EwYCLJZtHGlFrQ06GRxQjvWGGNURwwdV/F1LYUWr2fW6qx6P8YYY6N43YvhY9obWujipxvawvYUrXJL4YL7Xltnh0J7XXpt1ce5fLresxbaL9P7kV7b3vSdSxOHAF5+ftEDQGMKPQA0ptADQGMKPQA0ptADQGMKPQA0Nn97XWqDSpaK1qRdqa9t4jlWQlte1bKX2vzWQyvcmdDitRj2bRaT4cYYY2328rmNZ8O9ik1jjF3LK/W+XeF1V61mS6GVL90rfc3S57lYvFdpAuDKhHa9McbYs1JnsYWuut/usAfgwvGLHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoLH5e+b2FxPNxsjT5taeK/aEW1cteWOMsSe0eE2x+ZUQhiy1aq2E8z9TR2dOzL7o0bW6ve5kmEK3slKf//o99fv/6v1T3uMw6e9kaCmMw9+qfWFyYPxGh8l25b3GGGfCtj3FZ50mKaZs7A0ZwPb5RQ8AjSn0ANCYQg8AjSn0ANCYQg8AjSn0ANDY/O11h19XZ+uhNWk9tN5VVtKUtNU62123mo1TxbS5tdCqtRSutxpeV5pQF4b2HTs2+4yfOVW3Yz11sm5rW1osWhvHGJ9fqfvaDhbtZKub9WteOlG38q0s1pP+9mzW599TtTduhPa0fWm64dV1lrralsP9NovXlqbypZbCfdrrgJ3lFz0ANKbQA0BjCj0ANKbQA0BjCj0ANDb/U/cHrglheio57SvEU8UpKOEcxfpGGMYywhP+Z8LAm3N19Mhj9YCaex+anX3my/W9Hjv+eJmth6E8y2HAy+HD181cPxg6L1YPzd4zxhiHwtCjlcX681xdnt31sBi6GlaLwUBjjPGaw6EbYoShTWfW6mxvcf7QXZHm54x9IQOYwC96AGhMoQeAxhR6AGhMoQeAxhR6AGhMoQeAxuZvrxu7d/gOfxk2nYf//VG1Oy2GQSdn6qEw48yVZXTuZN0/de/HPllmv/no52auf2aslXtOx16taT5+7KGZ69cce3255/qlm8rsSGjLu/ZAPcBoeWl269qu0M65uq9uk1tZr4fr7F9/Olyz/qxfXQ10Wim3jLFnG//sAF4iv+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAam7/PZ/NMnW2E6XVVK9RSuHWYaDbG7IlmL6q6XTp66lwLr/nEU3Vb3hPH6ul1fzKembn+fDjGhfSl8dk626izTx1dKbNrj9atd4eWZrfKreyrR8MtL4VJeat1K9/qsbrN8tCB+poHD63MXL9+pf6e7ll8ocx233JDmQFM4Rc9ADSm0ANAYwo9ADSm0ANAYwo9ADSm0ANAY/O31/3cL9bZZupRK+wLU+OOXFNnq6+psz2hLe9M0Su3WU80G9VksjFGeutes69u47r+QD1dbf9jfzpz/fHYA3jxOx2m7316zJ6UN8YYny7e/iueWij37B/192P/Y/V7f2DpujI7eDh8ZgdmT7Z7eHml3LM7fE3/wffcXYcAE/hFDwCNKfQA0JhCDwCNKfQA0JhCDwCNKfQA0NjC1tbW1jz/4alv/KYyOxemce1avGLm+t7UQvcNd9bZG2+qs6XZrU5jjDE2vjJ7PbUGbqQJe7Nf1xhjjBP19LpT99XtZD/zS781c/0Dxx4o93ypPgXbcPVYLbPVUbeCLo/Z34PFbXSu/t/+cOuPJ+27GC0s1G2QwM6Yp4T7RQ8AjSn0ANCYQg8AjSn0ANCYQg8AjSn0ANDY3D1Ax088Oe0Gi7NvsXe1bmcaZ9bq7MTTdbY7tNedfX72+mIYJba7nkI3ll9ZZ4frdqy9+1bK7Ef2zn6vVn+1/ph+4ZP3lVmfRq3z7+lxssyeCVmlbjgFuLD8ogeAxhR6AGhMoQeAxhR6AGhMoQeAxuZ+6v6mO9+ys3c+uDxt38l6YMwYp+uoGl5TdAWMMcY4FAbXpKful8M13/jaMtq1NHuYz/eH6x06VD/h/4HfuKfMfmuslRlfzRP0wKXML3oAaEyhB4DGFHoAaEyhB4DGFHoAaEyhB4DG5m6vG6sT2+Equ19RZxvFAJoxxjgRWujW1+vszFdmr+8LbXJh3s1IQ3k2N8I1w1u+Wpzl1pvKLXeNom1wjPHUyfr9OHbfh8rs02UCwKXGL3oAaEyhB4DGFHoAaEyhB4DGFHoAaEyhB4DG5m6vO/vwI9PusDR7AtzuvaFdb39oeUvT5jZDW17VaRZb4V5VZyvPhn2hdTCdf71olTsTXlc4/oHQynd41O//nxVvVjgFABcpv+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAam7u97kMf/ViZ1fPTaqurK2V2w831tLYD+68qs117J7TlLaYRdaGhbG2tzp6Z3VL4ok4U93v0c+WWRx94qM4eerDMTpX9hvXQPu1180vfgDD3EGDH+UUPAI0p9ADQmEIPAI0p9ADQmEIPAI0p9ADQ2NztdQ+HLLXXVcPVVk+u1XserNvCFm+9vcxeszdMmzt0TbFet+uNMP0tOv5cnZ0IU++OPTlz+QthcuAffOyBOluvR9v9j/oU44WQVVI72ZTrdTalHRVgKr/oAaAxhR4AGlPoAaAxhR4AGlPoAaCxuR8r/3LI6me7xzhVrO9LN1uvn0te+lw94GXfav3U/a4jxVP30Svq6FQY8bL+dJ09+oUyeuTR2QNq7r3vT8s9v1nfaXw8ZDvtUniyPvRkjOWQpe/3yWI9vR+hJwNgx/lFDwCNKfQA0JhCDwCNKfQA0JhCDwCNKfQA0Njc7XVPhWzKUJvUspQshWE4y5+4v8zurO545631zZZD09XJejjN2UfqFsB7768H9tx7fH3m+h/UpxifDRnzWwlZ+n7P/sTGCM2XABeUX/QA0JhCDwCNKfQA0JhCDwCNKfQA0JhCDwCNzd1eV03pejFV+1GSWu9iK9/xtfocH/69meu3rdeNUMsrS2V2/OjjZfaRR79UZveWSZ2dDnuYX5oaV3/SmTY64GLnFz0ANKbQA0BjCj0ANKbQA0BjCj0ANKbQA0Bjc7fXTWmTG6Nuh0vXS1lqr0svZmlja/a9PvpAfb1wwcfCQe4J5/j9kPHyWQvZ1EmLABcDv+gBoDGFHgAaU+gBoDGFHgAaU+gBoDGFHgAam7u9LrW1JVWrXJrIdkXIVkKWzrhWrD+W9oQLfj7s+1TIuDiZQgd05Rc9ADSm0ANAYwo9ADSm0ANAYwo9ADQ291P3z0y8wQs7vCc9WZ+yajDJWtiThuucmngOALiQ/KIHgMYUegBoTKEHgMYUegBoTKEHgMYUegBobO72uiltcufDWsiOhax6ofsnnuNAyK4N2Wcn3g8ApvCLHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoLGFra2trbn+w4WF832W8+rqYv3asGdvyJZCVk3KG2OMoyF7PGRcHub853hJuNT/ZsClYJ6/GX7RA0BjCj0ANKbQA0BjCj0ANKbQA0BjCj0ANHbZtNfttFeFbCVkmyH7crF+sUwOnKpqbXwxT+/oKcZ4ZcjeFLL0mX182lFK2uuA7dBeBwCXOYUeABpT6AGgMYUeABpT6AGgMYUeABpbfLkPcKl6bmLW1feF7K4j15XZ/kN1o+IzJ2a/k888Vb/D5zbq2YH79tb3Wj1YNwFurNcNdkefenLm+h+tnyz3nCgTgJ3nFz0ANKbQA0BjCj0ANKbQA0BjCj0ANKbQA0Bjc7fXfd0O32At7Pl8yC71SW5TfG3IjoRsKWRpIttKsf6GpfqKb3/bW8rsa+58fX2z5TAHMLTKlU6d3v6eMcZYvHLStrvXZ7f6/cX6s+Wejc0JrwtgIr/oAaAxhR4AGlPoAaAxhR4AGlPoAaCxuZ+6/5Hl9J/Wz3BX80COhwePPxPudG/Ing7ZFK8M2WrIDoZsyhShQyF7Q8iOrC6X2cFD9RCX/YdeO3N93776Ve9aDU+tn12vs3Ph+f/dxTXD6xqrE3sNUhvCRvjU9szOXn02XA/gAvKLHgAaU+gBoDGFHgAaU+gBoDGFHgAaU+gBoLG5u73efOvNZbY5ni+zk0Uf3fLxuhlus+rJG2McK5PcIVU1eE1tkzsc9y2EdKtMqjOmhrE9Idu/px4Yc6RooRtjjD1HrpkdLIe2ts3QQrcRPpnlsG9zwqCZpbBns/6eTrZYvLbd6VMDuHD8ogeAxhR6AGhMoQeAxhR6AGhMoQeAxhR6AGhsYWtrq+73AgAuaX7RA0BjCj0ANKbQA0BjCj0ANKbQA0BjCj0ANKbQA0BjCj0ANKbQA0Bj/wtKDln3IdaqMQAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,\n",
    "                                                                                num_workers = config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                standardized_to_imagenet=True,\n",
    "                                                                                augment_val_set = True,\n",
    "                                                                                prefetch_factor=config.INFO[\"prefetch_factor\"],\n",
    "                                                                                aug_pkg = config.DATA[\"augmentation_package\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))\n",
    "print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nconfig.SSL[\"exclude_bn_bias_from_weight_decay\"]\\n# check if the sub module is the same as needed\\nfor name, module in ssl_model.backbone.named_modules():\\n    print(name, \":\", module)\\n# check if the bachnorm is correctly converted to sync batchnorm\\n\\n\\nssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\\nfor name, module in ssl_model.backbone.named_modules():\\n    if isinstance(module, torch.nn.BatchNorm2d):\\n        print(f\"No BatchNorm2d NOT converted at: {name}\")\\n    elif isinstance(module, torch.nn.SyncBatchNorm):\\n        print(f\"Yes SyncBatchNorm converted at: {name}\")\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  loss_name= config.SSL[\"loss_function\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  scheduler_name = config.SSL[\"lr_scheduler\"],\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  restart_epochs = config.SSL[\"restart_epochs\"],\n",
    "                                  exclude_bn_bias_from_weight_decay  =  config.SSL[\"exclude_bn_bias_from_weight_decay\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = ssl_batch_size,\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])\n",
    "'''\n",
    "config.SSL[\"exclude_bn_bias_from_weight_decay\"]\n",
    "# check if the sub module is the same as needed\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    print(name, \":\", module)\n",
    "# check if the bachnorm is correctly converted to sync batchnorm\n",
    "\n",
    "\n",
    "ssl_model.backbone = torch.nn.SyncBatchNorm.convert_sync_batchnorm(ssl_model.backbone)\n",
    "for name, module in ssl_model.backbone.named_modules():\n",
    "    if isinstance(module, torch.nn.BatchNorm2d):\n",
    "        print(f\"No BatchNorm2d NOT converted at: {name}\")\n",
    "    elif isinstance(module, torch.nn.SyncBatchNorm):\n",
    "        print(f\"Yes SyncBatchNorm converted at: {name}\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/plugins/precision/amp.py:52: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3060') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clap/simulations/ssl exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 12.7 M | train\n",
      "-------------------------------------------------\n",
      "12.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.7 M    Total params\n",
      "50.976    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fbdb9c14b1409fb737306dc1f26764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/lightning_fabric/utilities/cloud_io.py:57: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58125fe9-0b8d-4f23-87c6-8ce3b733ebce",
   "metadata": {},
   "outputs": [],
   "source": [
    "backbone_ckpt = os.path.join(ssl_dir,\"last_epoch_backbone_\" + config.SSL[\"backbone\"] +\".ckpt\")\n",
    "if not os.path.isfile(backbone_ckpt):\n",
    "    torch.save(ssl_model.backbone.net.state_dict(),backbone_ckpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clap/simulations/lc/lr_0.3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "445abc4d58204b92b2f4c46ec99ef4fe",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: simulations/lc/lr_0.3/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97a02a45608846fea7c5fd49ceb1cc79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.3425999879837036\n",
      "     batch_test_acc5         0.836899995803833\n",
      "     batch_test_loss         1.981158971786499\n",
      "        test_acc1           0.3425999879837036\n",
      "        test_acc5            0.836899995803833\n",
      "        test_loss           1.9811593294143677\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clap/simulations/lc/lr_0.1 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca644d5cf1b843129d1b616983f45c50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: simulations/lc/lr_0.1/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d6c2d4254df4c65965490ec00042fa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.35019999742507935\n",
      "     batch_test_acc5        0.8521999716758728\n",
      "     batch_test_loss         1.812874436378479\n",
      "        test_acc1           0.35019999742507935\n",
      "        test_acc5           0.8521999716758728\n",
      "        test_loss           1.8128749132156372\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/guanming/Documents/clap/simulations/lc/lr_0.05 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 11.2 M | train\n",
      "1 | linear_net | Linear      | 5.1 K  | train\n",
      "---------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.696    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lw2 is dummy for RepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "815b168883b04eaaa559c86584f481e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: simulations/lc/lr_0.05/lightning_logs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2e0062c9c8f41ac873817ddfbf47a52",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1        0.36550000309944153\n",
      "     batch_test_acc5        0.8784999847412109\n",
      "     batch_test_loss        1.7311253547668457\n",
      "        test_acc1           0.36550000309944153\n",
      "        test_acc5           0.8784999847412109\n",
      "        test_loss           1.7311257123947144\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"n_trans\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":[config.DATA[\"crop_size\"][0]],\"crop_min_scale\":[0.08],\"crop_max_scale\":[1.0],\"hflip_prob\":[0.5]}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    latest_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "    ssl_model = lightning_models.CLAP.load_from_checkpoint(latest_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = ssl_model.backbone.feature_dim,\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lc_dir' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mlc_dir\u001b[49m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lc_dir' is not defined"
     ]
    }
   ],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__init__() missing 1 required positional argument: 'scheduler_name'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 47\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# load the best linear classifier from the checkpoint\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m#with open(os.path.join(lc_dir,\"results.json\")) as f:\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m#    results = json.load(f)\u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m#    best_lc_dir = results[\"best_model_dir\"] \u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m#lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\u001b[39;00m\n\u001b[1;32m     46\u001b[0m linear_net \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mLinear(\u001b[38;5;241m2048\u001b[39m,\u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m---> 47\u001b[0m semisl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFineTune\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbackbone\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mssl_model\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackbone\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_net\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mlinear_net\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptim_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msemisl_lr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     51\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmomentum\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmomentum\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSemiSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     54\u001b[0m semisl_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mtrain_finetune(\n\u001b[1;32m     55\u001b[0m         finetune_model \u001b[38;5;241m=\u001b[39m semisl_model,\n\u001b[1;32m     56\u001b[0m         train_loader \u001b[38;5;241m=\u001b[39m semisl_test_loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m         precision\u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mINFO[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mprecision\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     63\u001b[0m         restart \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mSemiSL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrestart_training\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# get the best performed one\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: __init__() missing 1 required positional argument: 'scheduler_name'"
     ]
    }
   ],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\n",
    "                     \"batch_size\":semisl_batch_size,\n",
    "                     \"n_views\":1,\n",
    "                     \"n_trans\":1,\n",
    "                     \"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                     \"crop_size\":config.DATA[\"crop_size\"],\n",
    "                     \"crop_min_scale\":[0.08],\n",
    "                     \"crop_max_scale\":[1.0],\n",
    "                     \"hflip_prob\":[0.5]}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            latest_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(latest_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            #with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "            #    results = json.load(f)\n",
    "            #    best_lc_dir = results[\"best_model_dir\"] \n",
    "            #lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            linear_net = torch.nn.Linear(2048,1000)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "[{'mean4norm': [0.5071, 0.4867, 0.4408], 'std4norm': [0.2675, 0.2565, 0.2761], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-CIFAR100/lr_0.1/best_val.ckpt, loading...\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FOOD101/lr_0.1/best_val.ckpt, loading...\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-FLOWERS102/lr_0.1/best_val.ckpt, loading...\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.005/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.01/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.05/best_val.ckpt, loading...\n",
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "Found pretrained model at ./simulation_imagenet/tl-DTD/lr_0.1/best_val.ckpt, loading...\n",
      "Using downloaded and verified file: ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar\n",
      "Extracting ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar to ./datasets/pascalvoc\n",
      "Using downloaded and verified file: ./datasets/pascalvoc/VOCtest_06-Nov-2007.tar\n",
      "Extracting ./datasets/pascalvoc/VOCtest_06-Nov-2007.tar to ./datasets/pascalvoc\n",
      "Using downloaded and verified file: ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar\n",
      "Extracting ./datasets/pascalvoc/VOCtrainval_06-Nov-2007.tar to ./datasets/pascalvoc\n",
      "[{'mean4norm': [0.485, 0.456, 0.406], 'std4norm': [0.229, 0.224, 0.225], 'crop_size': 224, 'crop_min_scale': 0.08, 'crop_max_scale': 1.0, 'hflip_prob': 0.5}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/lightning_fabric/loggers/csv_logs.py:269: Experiment logs directory ./simulation_imagenet/tl-PascalVOC/lr_0.005/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_mem_size is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n",
      "lw2 is dummy for LogRepulsiveEllipsoidPackingLossUnitNorm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 23.5 M | train\n",
      "1 | linear_net | Linear      | 41.0 K | train\n",
      "---------------------------------------------------\n",
      "23.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "23.5 M    Total params\n",
      "94.196    Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bda31decb7b24747959ddb21ea1611ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 183, in collate\n    clone[i] = collate(samples, collate_fn_map=collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 170, in collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 55\u001b[0m\n\u001b[1;32m     41\u001b[0m ssl_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mremove_projection_head()\n\u001b[1;32m     43\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mLinearClassification(\n\u001b[1;32m     44\u001b[0m         backbone \u001b[38;5;241m=\u001b[39m ssl_model\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[1;32m     45\u001b[0m         in_dim \u001b[38;5;241m=\u001b[39m ssl_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mfeature_dim,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m         weight_decay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     53\u001b[0m         n_epochs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 55\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_lc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     56\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mevery_n_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_every_n_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     63\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_sub_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrestart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrestart_training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     65\u001b[0m             \u001b[38;5;66;03m# get the best performed one\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(tl_sub_dir,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults.json\u001b[39m\u001b[38;5;124m\"\u001b[39m)) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[0;32m~/Documents/clap/model/lightning_models.py:600\u001b[0m, in \u001b[0;36mtrain_lc\u001b[0;34m(linear_model, train_loader, test_loader, val_loader, max_epochs, every_n_epochs, checkpoint_path, num_nodes, gpus_per_node, strategy, precision, restart, if_profile)\u001b[0m\n\u001b[1;32m    598\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mfit(linear_model, train_loader,val_loader,ckpt_path\u001b[38;5;241m=\u001b[39mckpt_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    599\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 600\u001b[0m     \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;66;03m# load the model with the best validation accuracy to avoid overfitting\u001b[39;00m\n\u001b[1;32m    602\u001b[0m linear_model \u001b[38;5;241m=\u001b[39m LinearClassification\u001b[38;5;241m.\u001b[39mload_from_checkpoint(trained_filename,backbone \u001b[38;5;241m=\u001b[39m linear_model\u001b[38;5;241m.\u001b[39mbackbone) \u001b[38;5;66;03m# Load best checkpoint after training\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:543\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    541\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 543\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    544\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    545\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/call.py:44\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     43\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 44\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     47\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:579\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    572\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    573\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    575\u001b[0m     ckpt_path,\n\u001b[1;32m    576\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    577\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    578\u001b[0m )\n\u001b[0;32m--> 579\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:986\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    981\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 986\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    988\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    989\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    990\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    991\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1028\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1027\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1028\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1029\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1030\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/trainer/trainer.py:1057\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1057\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1061\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/utilities.py:182\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    180\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 182\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/pytorch_lightning/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1344\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1342\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1343\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1344\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/dataloader.py:1370\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1368\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1369\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1370\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/_utils.py:706\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    702\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    703\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    704\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    705\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 706\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/worker.py\", line 309, in _worker_loop\n    data = fetcher.fetch(index)  # type: ignore[possibly-undefined]\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\", line 55, in fetch\n    return self.collate_fn(data)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 317, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 174, in <listcomp>\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 183, in collate\n    clone[i] = collate(samples, collate_fn_map=collate_fn_map)\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in collate\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 155, in <dictcomp>\n    clone.update({key: collate([d[key] for d in batch], collate_fn_map=collate_fn_map) for key in elem})\n  File \"/home/guanming/miniconda3/envs/mydl/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\", line 170, in collate\n    raise RuntimeError('each element in list of batch should be of equal size')\nRuntimeError: each element in list of batch should be of equal size\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102,\n",
    "                    \"DTD\":47}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\",\"DTD\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\n",
    "                     \"batch_size\":tl_batch_size,\n",
    "                     \"n_views\":1,\n",
    "                     \"n_trans\":1,\n",
    "                     \"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                     \"crop_size\":config.DATA[\"crop_size\"],\n",
    "                     \"crop_min_scale\":[0.08],\n",
    "                     \"crop_max_scale\":[1.0],\n",
    "                     \"hflip_prob\":[0.5]}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,batch_size=10,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            latest_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(latest_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = ssl_model.backbone.feature_dim,\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
