{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[FT]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = auto\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 8\n",
      "augmentations = ['RandomResizeCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 1\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "backbone_out_dim = 2048\n",
      "use_projection_head = True\n",
      "proj_dim = 2048\n",
      "proj_out_dim = 256\n",
      "optimizer = LARS\n",
      "lr = 0.1\n",
      "lr_scale = linear\n",
      "momentum = 0.99\n",
      "weight_decay = 0.1\n",
      "lars_eta = 0.1\n",
      "loss_function = EllipsoidPackingLoss\n",
      "lw0 = 1.0\n",
      "lw1 = 1.0\n",
      "lw2 = 1.0\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 2\n",
      "batch_size = 64\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "\n",
      "[LC]\n",
      "optimizer = SGD\n",
      "use_batch_norm = True\n",
      "lr = 0.1\n",
      "lr_scale = linear\n",
      "weight_decay = 0.0001\n",
      "momentum = 0.99\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 2\n",
      "save_every_n_epochs = 1\n",
      "batch_size = 128\n",
      "apply_simple_augmentations = True\n",
      "restart_training = False\n",
      "output_dim = 10\n",
      "\n",
      "[FT]\n",
      "loss_function = CrossEntropyLoss\n",
      "apply_simple_augmentations = True\n",
      "optimizer = SGD\n",
      "lr = 24.0\n",
      "lr_scale = linear\n",
      "momentum = 0.9\n",
      "weight_decay = 0.0\n",
      "n_epochs = 2\n",
      "batch_size = 256\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "\n",
      "[TL]\n",
      "output_dim = 10\n",
      "optimizer = SGD\n",
      "use_batch_norm = False\n",
      "lr = 0.1\n",
      "lr_scale = linear\n",
      "weight_decay = 0.0001\n",
      "momentum = 0.0\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 2\n",
      "save_every_n_epochs = 50\n",
      "batch_size = 256\n",
      "apply_simple_augmentations = True\n",
      "restart_training = False\n",
      "\n"
     ]
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "#config = helper.Config(\"./simulation1\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "781\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],validation=False)\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "del ssl_val_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  backbone_out_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = config.SSL[\"batch_size\"],\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulations/ssl/ssl-epoch=1.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Found pretrained model at ./simulations/lc/best_val.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "if config.LC[\"apply_simple_augmentations\"]:\n",
    "    data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizeCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "else:\n",
    "    data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[]}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"])\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if config.LC[\"lr_scale\"] == \"linear\":\n",
    "    lc_lr = config.LC[\"lr\"]*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "    lc_lr = config.LC[\"lr\"]*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "# load the backbone from the check point\n",
    "last_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "ssl_model = lightning_models.CLAP.load_from_checkpoint(last_ssl_ckpt)\n",
    "ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "lc_model = lightning_models.LinearClassification(\n",
    "                 backbone= ssl_model.backbone,\n",
    "                 in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "#lc_model.set_backbone(ssl_model.backbone)\n",
    "lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'imagenet_train_dir'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 11\u001b[0m\n\u001b[1;32m      9\u001b[0m     data_info \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdataset\u001b[39m\u001b[38;5;124m\"\u001b[39m:dataset,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m:ft_batch_size,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_views\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m1\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maugmentations\u001b[39m\u001b[38;5;124m\"\u001b[39m:[]}\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# add the location for imagenet dataset\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet_train_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATA\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimagenet_train_dir\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m     12\u001b[0m data_info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet_val_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mDATA[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagenet_val_dir\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     13\u001b[0m ft_train_loader,ft_test_loader,ft_val_loader \u001b[38;5;241m=\u001b[39m data_utils\u001b[38;5;241m.\u001b[39mget_dataloader(data_info,ft_batch_size,num_workers\u001b[38;5;241m=\u001b[39mconfig\u001b[38;5;241m.\u001b[39mINFO[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpus_per_gpu\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "\u001b[0;31mKeyError\u001b[0m: 'imagenet_train_dir'"
     ]
    }
   ],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1%\",\"IMAGENET1K-10%\"]:\n",
    "        if config.SemiSL[\"apply_simple_augmentations\"]:\n",
    "            data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":2,\"augmentations\":[\"RandomResizeCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        else:\n",
    "            data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[]}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "            semisl_lr = config.SemiSL[\"lr\"]*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "        elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "            semisl_lr = config.SemiSL[\"lr\"]*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "        # load the backbone from the checkpoint\n",
    "        last_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "        ssl_model = lightning_models.CLAP.load_from_checkpoint(last_ssl_ckpt)\n",
    "        ssl_model.backbone.remove_projection_head()\n",
    "        # load the linear classifier from the checkpoint\n",
    "        last_lc_ckpt = lightning_models.get_top_n_latest_checkpoints(lc_dir,1)[0]\n",
    "        lc_model = lightning_models.LinearClassification.load_from_checkpoint(last_lc_ckpt,backbone = ssl_model.backbone)\n",
    "        semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= lc_model.linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.LC[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "        semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/tl-CIFAR100 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 12.2 M | train\n",
      "1 | linear_net | Linear      | 204 K  | train\n",
      "---------------------------------------------------\n",
      "12.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.4 M    Total params\n",
      "49.697    Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fitting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18d11445a4db46ed95788a95b8550bdc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a955e41e16054b72bbff3eb4c2a9e096",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef766df4463243a58bc61ba17816dc89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "967b8927bcfe42bbb70456adc1a9fb69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5360fb216d834da1b29e46ffe6d4ebae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "       Test metric             DataLoader 0\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n",
      "     batch_test_acc1       0.009915865026414394\n",
      "     batch_test_acc5        0.04997996613383293\n",
      "     batch_test_loss         4.605038166046143\n",
      "        test_acc1          0.009915865957736969\n",
      "        test_acc5           0.04997996985912323\n",
      "        test_loss            4.605038642883301\n",
      "────────────────────────────────────────────────────────────────────────────────────────────────────────────────────────\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/tl-FOOD101 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 12.2 M | train\n",
      "1 | linear_net | Linear      | 206 K  | train\n",
      "---------------------------------------------------\n",
      "12.4 M    Trainable params\n",
      "0         Non-trainable params\n",
      "12.4 M    Total params\n",
      "49.706    Total estimated model params size (MB)\n",
      "71        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start fitting\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19b242c6174644819af39a01c88a59d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 144, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 147, in collate\n    return elem_type([collate(samples, collate_fn_map=collate_fn_map) for samples in transposed])\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 125, in collate\n    return collate_fn_map[collate_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 173, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 39\u001b[0m\n\u001b[1;32m     26\u001b[0m ssl_model\u001b[38;5;241m.\u001b[39mbackbone\u001b[38;5;241m.\u001b[39mremove_projection_head()\n\u001b[1;32m     28\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mLinearClassification(\n\u001b[1;32m     29\u001b[0m             backbone \u001b[38;5;241m=\u001b[39m ssl_model\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[1;32m     30\u001b[0m             in_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mSSL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone_out_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     36\u001b[0m             weight_decay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     37\u001b[0m             n_epochs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mTL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 39\u001b[0m tl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_lc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     40\u001b[0m \u001b[43m            \u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     42\u001b[0m \u001b[43m            \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtest_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_test_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[43m            \u001b[49m\u001b[43mevery_n_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_every_n_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     45\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m            \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtl_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrestart\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mLC\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrestart_training\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m \n\u001b[1;32m     51\u001b[0m lc_model \u001b[38;5;241m=\u001b[39m lightning_models\u001b[38;5;241m.\u001b[39mLinearClassification(\n\u001b[1;32m     52\u001b[0m          backbone\u001b[38;5;241m=\u001b[39m ssl_model\u001b[38;5;241m.\u001b[39mbackbone,\n\u001b[1;32m     53\u001b[0m          in_dim \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mSSL[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbackbone_out_dim\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     59\u001b[0m          weight_decay \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweight_decay\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     60\u001b[0m          n_epochs \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mLC[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_epochs\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[0;32m~/Documents/code/clap/model/lightning_models.py:375\u001b[0m, in \u001b[0;36mtrain_lc\u001b[0;34m(linear_model, train_loader, test_loader, val_loader, max_epochs, every_n_epochs, checkpoint_path, num_nodes, gpus_per_node, strategy, precision, restart)\u001b[0m\n\u001b[1;32m    373\u001b[0m     linear_model \u001b[38;5;241m=\u001b[39m  LinearClassification\u001b[38;5;241m.\u001b[39mload_from_checkpoint(ckpt_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    374\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart fitting\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 375\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    376\u001b[0m test_output \u001b[38;5;241m=\u001b[39m trainer\u001b[38;5;241m.\u001b[39mtest(linear_model,test_loader)\n\u001b[1;32m    377\u001b[0m result \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m:test_output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_loss\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    378\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc1\u001b[39m\u001b[38;5;124m\"\u001b[39m:test_output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc1\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    379\u001b[0m           \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc5\u001b[39m\u001b[38;5;124m\"\u001b[39m:test_output[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_acc5\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    380\u001b[0m         }\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     50\u001b[0m     _call_teardown_hook(trainer)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    567\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    976\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_signal_connector\u001b[38;5;241m.\u001b[39mregister_signal_handlers()\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    986\u001b[0m log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: trainer tearing down\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1023\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining:\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m isolate_rng():\n\u001b[0;32m-> 1023\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_sanity_check\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[1;32m   1025\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit_loop\u001b[38;5;241m.\u001b[39mrun()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1052\u001b[0m, in \u001b[0;36mTrainer._run_sanity_check\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1049\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_start\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1051\u001b[0m \u001b[38;5;66;03m# run eval step\u001b[39;00m\n\u001b[0;32m-> 1052\u001b[0m \u001b[43mval_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1054\u001b[0m call\u001b[38;5;241m.\u001b[39m_call_callback_hooks(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mon_sanity_check_end\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;66;03m# reset logger connector\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/utilities.py:178\u001b[0m, in \u001b[0;36m_no_grad_context.<locals>._decorator\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     context_manager \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mno_grad\n\u001b[1;32m    177\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context_manager():\n\u001b[0;32m--> 178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/evaluation_loop.py:128\u001b[0m, in \u001b[0;36m_EvaluationLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    126\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    127\u001b[0m     dataloader_iter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 128\u001b[0m     batch, batch_idx, dataloader_idx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m previous_dataloader_idx \u001b[38;5;241m!=\u001b[39m dataloader_idx:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;66;03m# the dataloader has changed, notify the logger connector\u001b[39;00m\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_store_dataloader_outputs()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:133\u001b[0m, in \u001b[0;36m_PrefetchDataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    130\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatches\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;66;03m# this will run only when no pre-fetching was done.\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__next__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;66;03m# the iterator is empty\u001b[39;00m\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fetchers.py:60\u001b[0m, in \u001b[0;36m_DataFetcher.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_start_profiler()\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 60\u001b[0m     batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdone \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:341\u001b[0m, in \u001b[0;36mCombinedLoader.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__next__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m _ITERATOR_RETURN:\n\u001b[1;32m    340\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 341\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    342\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iterator, _Sequential):\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/utilities/combined_loader.py:142\u001b[0m, in \u001b[0;36m_Sequential.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    139\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 142\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterators\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    144\u001b[0m     \u001b[38;5;66;03m# try the next iterator\u001b[39;00m\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_next_iterator()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1346\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1344\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1345\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_task_info[idx]\n\u001b[0;32m-> 1346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/dataloader.py:1372\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._process_data\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m   1370\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_try_put_index()\n\u001b[1;32m   1371\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ExceptionWrapper):\n\u001b[0;32m-> 1372\u001b[0m     \u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1373\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/_utils.py:722\u001b[0m, in \u001b[0;36mExceptionWrapper.reraise\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[1;32m    719\u001b[0m     \u001b[38;5;66;03m# If the exception takes multiple arguments, don't try to\u001b[39;00m\n\u001b[1;32m    720\u001b[0m     \u001b[38;5;66;03m# instantiate since we don't know how to\u001b[39;00m\n\u001b[1;32m    721\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 722\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m exception\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Caught RuntimeError in DataLoader worker process 0.\nOriginal Traceback (most recent call last):\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/worker.py\", line 308, in _worker_loop\n    data = fetcher.fetch(index)\n           ^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/fetch.py\", line 54, in fetch\n    return self.collate_fn(data)\n           ^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 277, in default_collate\n    return collate(batch, collate_fn_map=default_collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 144, in collate\n    return [collate(samples, collate_fn_map=collate_fn_map) for samples in transposed]  # Backwards compatibility.\n            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 147, in collate\n    return elem_type([collate(samples, collate_fn_map=collate_fn_map) for samples in transposed])\n                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 125, in collate\n    return collate_fn_map[collate_type](batch, collate_fn_map=collate_fn_map)\n           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n  File \"/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/utils/data/_utils/collate.py\", line 173, in collate_tensor_fn\n    out = elem.new(storage).resize_(len(batch), *list(elem.size()))\n          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\nRuntimeError: Trying to resize storage that is not resizable\n"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        if config.LC[\"apply_simple_augmentations\"]:\n",
    "            data_info = {\"dataset\":dataset,\"batch_size\":tl_batch_size,\"n_views\":2,\"augmentations\":[\"Resize\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5,\"resize_to\":224}\n",
    "        else:\n",
    "            data_info = {\"dataset\":config.INFO[\"dataset\"],\"batch_size\":tl_batch_size,\"n_views\":1,\"augmentations\":[\"Resize\"],\"resize_to\":224}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "\n",
    "        if config.TL[\"lr_scale\"] == \"linear\":\n",
    "            tl_lr = config.TL[\"lr\"]*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "        elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "            tl_lr = config.TL[\"lr\"]*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "\n",
    "        # load the backbone from the checkpoint\n",
    "        last_ssl_ckpt = lightning_models.get_top_n_latest_checkpoints(ssl_dir,1)[0]\n",
    "        ssl_model = lightning_models.CLAP.load_from_checkpoint(last_ssl_ckpt)\n",
    "        ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "        tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "        tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "        \n",
    "\n",
    "        lc_model = lightning_models.LinearClassification(\n",
    "                 backbone= ssl_model.backbone,\n",
    "                 in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
