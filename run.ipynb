{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6fdc4670-6643-4540-9fd9-3e9c5edb4c4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 2.0.0 (you have 1.4.23). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "from utils import data_utils\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import training_utils\n",
    "from utils import data_utils\n",
    "import torch\n",
    "from model import models\n",
    "import json\n",
    "import os\n",
    "from model import lightning_models\n",
    "import math\n",
    "import pytorch_lightning as pl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b548de5c-edbb-4da6-8e44-3f8e45615cd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading default settings...\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[SemiSL]does not exist in the config file\n",
      "[TL]does not exist in the config file\n",
      "[INFO]\n",
      "num_nodes = 1\n",
      "gpus_per_node = 1\n",
      "cpus_per_gpu = 8\n",
      "prefetch_factor = 2\n",
      "precision = 16-mixed\n",
      "fix_random_seed = True\n",
      "strategy = auto\n",
      "if_profile = True\n",
      "\n",
      "[DATA]\n",
      "dataset = CIFAR10\n",
      "n_views = 8\n",
      "augmentations = ['RandomResizedCrop', 'GaussianBlur', 'RandomGrayscale', 'ColorJitter', 'RandomHorizontalFlip']\n",
      "augmentation_package = albumentations\n",
      "crop_size = 32\n",
      "crop_min_scale = 0.08\n",
      "crop_max_scale = 1.0\n",
      "hflip_prob = 0.5\n",
      "blur_kernel_size = 1\n",
      "blur_prob = 0.5\n",
      "grayscale_prob = 0.2\n",
      "jitter_brightness = 0.8\n",
      "jitter_contrast = 0.8\n",
      "jitter_saturation = 0.8\n",
      "jitter_hue = 0.2\n",
      "jitter_prob = 0.8\n",
      "\n",
      "[SSL]\n",
      "backbone = resnet18\n",
      "backbone_out_dim = 2048\n",
      "use_projection_head = True\n",
      "proj_dim = 2048\n",
      "proj_out_dim = 128\n",
      "optimizer = LARS\n",
      "lr = 0.8\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine-warmup\n",
      "grad_accumulation_steps = 1\n",
      "momentum = 0.0\n",
      "weight_decay = 0.0001\n",
      "lars_eta = 0.001\n",
      "loss_function = PackingLoss\n",
      "lw0 = 0.0\n",
      "lw1 = 1.0\n",
      "lw2 = 0.1\n",
      "pot_pow = 1.0\n",
      "rs = 3.0\n",
      "warmup_epochs = 1\n",
      "n_epochs = 5\n",
      "batch_size = 64\n",
      "save_every_n_epochs = 1\n",
      "restart_training = False\n",
      "\n",
      "[LC]\n",
      "output_dim = 10\n",
      "optimizer = SGD\n",
      "use_batch_norm = False\n",
      "lr = 0.2\n",
      "lr_scale = linear\n",
      "lr_scheduler = cosine\n",
      "weight_decay = 0.0\n",
      "momentum = 0.9\n",
      "loss_function = CrossEntropyLoss\n",
      "n_epochs = 6\n",
      "save_every_n_epochs = 3\n",
      "batch_size = 256\n",
      "apply_simple_augmentations = True\n",
      "standardize_to_imagenet = False\n",
      "restart_training = False\n",
      "lr_sweep = [0.1, 0.2, 0.3]\n",
      "\n",
      "lr overrided by lr_sweep!!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\n# save the starting time as the last line\\ncurrent_datetime,est_zone = helper.get_est_time_now()\\nif os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(\"\\n\")\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\nelse:\\n    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\\n        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\\n'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = helper.Config(\"./simulations\",default_config_file=\"./default_configs/default_config_cifar10.ini\")\n",
    "\n",
    "#config = helper.Config(\"./simulation_imagenet\",default_config_file=\"./default_configs/default_config_imagenet1k.ini\")\n",
    "\n",
    "if config.INFO[\"fix_random_seed\"]:\n",
    "    pl.seed_everything(137) # To be reproducable\n",
    "'''\n",
    "# save the starting time as the last line\n",
    "current_datetime,est_zone = helper.get_est_time_now()\n",
    "if os.path.isfile(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\")):\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(\"\\n\")\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "else:\n",
    "    with open(os.path.join(\"./simulation_imagenet\",\"starting-time.txt\"),\"a\") as f:\n",
    "        f.write(current_datetime.strftime(\"%Y-%m-%d %H:%M:%S\"))\n",
    "'''    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72a2a26b-d596-42f5-85d0-40e7bfe4ac4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703\n",
      "78\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for multi-gpu trainning, effective batch size = batch_size*num_gpus\n",
    "ssl_batch_size = config.SSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"]*config.SSL[\"grad_accumulation_steps\"])\n",
    "ssl_train_loader,ssl_test_loader,ssl_val_loader = data_utils.get_dataloader(config.DATA,ssl_batch_size,\n",
    "                                                                                num_workers = config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                standardized_to_imagenet=True,\n",
    "                                                                                augment_val_set = True,\n",
    "                                                                                prefetch_factor=config.INFO[\"prefetch_factor\"],\n",
    "                                                                                aug_pkg = config.DATA[\"augmentation_package\"])\n",
    "# test_loader and val_loader are not necessary\n",
    "del ssl_test_loader\n",
    "imgs,labels = next(iter(ssl_train_loader))\n",
    "img_list, label_list = [],[]\n",
    "for i_view in range(2):\n",
    "    for j_img in range(2):\n",
    "        img_list.append(imgs[i_view][j_img])\n",
    "        #label_list.append(classes[labels[i_view][j_img]])\n",
    "data_utils.show_images(img_list,2,2,label_list)\n",
    "print(len(ssl_train_loader))\n",
    "print(len(ssl_val_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "337f8759-849a-4733-a6d0-d0319d708929",
   "metadata": {},
   "outputs": [],
   "source": [
    "if config.SSL[\"lr_scale\"] == \"linear\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*config.SSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "elif config.SSL[\"lr_scale\"] == \"sqrt\":\n",
    "    ssl_lr = config.SSL[\"lr\"]*math.sqrt(config.SSL[\"batch_size\"]) # lr ~ 0.05\n",
    "if \"CIFAR\" in config.DATA[\"dataset\"] or \"MNIST\" in config.DATA[\"dataset\"]:\n",
    "    prune_backbone = True\n",
    "else:\n",
    "    prune_backbone = False\n",
    "ssl_model = lightning_models.CLAP(backbone_name = config.SSL[\"backbone\"],\n",
    "                                  backbone_out_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                                  prune = prune_backbone,\n",
    "                                  use_projection_head=config.SSL[\"use_projection_head\"],\n",
    "                                  proj_dim = config.SSL[\"proj_dim\"],\n",
    "                                  proj_out_dim = config.SSL[\"proj_out_dim\"],\n",
    "                                  loss_name= config.SSL[\"loss_function\"],\n",
    "                                  optim_name = config.SSL[\"optimizer\"],\n",
    "                                  lr = ssl_lr,\n",
    "                                  scheduler_name = config.SSL[\"lr_scheduler\"],\n",
    "                                  momentum = config.SSL[\"momentum\"],\n",
    "                                  weight_decay = config.SSL[\"weight_decay\"],\n",
    "                                  eta = config.SSL[\"lars_eta\"],\n",
    "                                  warmup_epochs = config.SSL[\"warmup_epochs\"],\n",
    "                                  n_epochs = config.SSL[\"n_epochs\"],\n",
    "                                  n_views = config.DATA[\"n_views\"],\n",
    "                                  batch_size = ssl_batch_size,\n",
    "                                  lw0 = config.SSL[\"lw0\"],\n",
    "                                  lw1 = config.SSL[\"lw1\"],\n",
    "                                  lw2 = config.SSL[\"lw2\"],\n",
    "                                  rs = config.SSL[\"rs\"],\n",
    "                                  pot_pow = config.SSL[\"pot_pow\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3edafb7-64e3-4c18-876f-a3900954832e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulations/ssl exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name     | Type        | Params | Mode \n",
      "-------------------------------------------------\n",
      "0 | backbone | BackboneNet | 16.7 M | train\n",
      "-------------------------------------------------\n",
      "16.7 M    Trainable params\n",
      "0         Non-trainable params\n",
      "16.7 M    Total params\n",
      "66.712    Total estimated model params size (MB)\n",
      "73        Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "983bef6678a94f4cb2a320b7d4e2e9c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1\n",
      "tensor(1342.1625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1464.9645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1350.1934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1472.0203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1393.0708, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1510.7719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1318.8779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1436.6796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1391.4268, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1509.3896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1406.1310, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1516.4379, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1377.2296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1491.4161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1374.7083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1476.9967, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1389.3752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1487.8668, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1308.4868, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1410.8961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1304.4260, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1405.9839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1307.4055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1402.1255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1312.4342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1401.0804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1334.5641, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1429.0514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1416.0410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1496.6703, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1309.9358, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1398.3208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1384.2054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1466.1056, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1352.1073, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1424.1104, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1328.8984, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1403.4149, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1304.2676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1379.5416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1324.5020, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1397.8362, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1320.3950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1390.2095, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1291.1973, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1359.8796, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1223.3934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1295.9657, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1348.6655, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1408.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1420.2115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1485.9688, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1359.4857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1422.8334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1336.1438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1400.8440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1326.9303, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1399.5620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1354.0320, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1422.6536, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1352.6846, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1418.7648, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1362.4731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1428.7939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1310.1588, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1372.4198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1234.1982, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1297.4908, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1296.0249, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1355.4684, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1284.8085, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1350.8131, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1319.4299, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1382.1565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1228.3691, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1283.6167, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1312.2959, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1370.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1295.7273, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1355.3650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1258.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1328.8176, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1257.2006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1327.3604, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1278.3911, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1339.1837, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1306.5631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1364.6414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1273.7097, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1334.8331, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1308.4396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1371.2889, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1210.5209, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1277.5663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1371.3275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1427.1770, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1252.9939, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1320.5565, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1281.3525, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1353.6830, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1187.3374, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1258.8752, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1246.4019, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1316.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1180.0652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1254.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1216.5398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1287.7264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1222.9961, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1292.3693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1146.7344, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1217.6578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1198.3871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1263.6754, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1239.6733, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1305.4386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1181.7898, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1251.9769, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1259.8301, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1326.8949, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1184.7920, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1252.6487, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1156.8176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1229.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1219.1660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1288.3824, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1257.3901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1326.9568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1240.1128, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1301.6233, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1214.1682, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1279.9344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1166.9825, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1235.9929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1231.6144, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1300.2800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1278.7156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1348.3888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1228.7751, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1297.7327, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1200.3052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1268.7410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1168.7528, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1241.0392, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1214.8948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1283.7650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1309.2986, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1369.6162, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1206.5326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1268.1226, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1195.5626, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1260.6185, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1160.9319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1227.7617, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1221.2820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1283.2549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1209.4382, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1276.3285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1229.3054, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1296.2570, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1194.0895, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1259.9165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1144.4729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1214.8794, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1243.6138, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1305.3284, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1155.3829, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1220.9105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1278.1166, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1345.0245, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1225.7839, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1294.3882, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1185.2184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1251.8602, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1113.2498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1181.9092, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1177.5947, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1244.3451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1178.5103, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1247.3606, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1154.4130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1221.5138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1195.9844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1264.8925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1156.9370, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1226.3093, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1099.1724, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1166.2388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1190.6714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1260.0420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1177.4561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1245.4813, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1170.7611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1243.8934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1173.2584, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1241.4021, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1145.5592, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1221.4103, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1151.9100, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1226.3019, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1151.5995, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1225.2885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1164.7131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1234.0612, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1150.1079, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1219.0334, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1161.5540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1233.8274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1103.0759, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1175.9386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1091.7422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1167.3939, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1135.3617, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1210.0878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1140.1941, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1214.2458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1117.3979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1188.0486, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1090.8212, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1163.2953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1018.1820, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1092.3986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1149.3611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1223.2583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1024.5052, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1102.6357, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1098.1903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1168.2198, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1092.6326, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1167.3833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1041.0879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1111.2649, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1054.7620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1127.4064, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1104.8979, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1178.1509, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1211.5681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1286.3459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1073.5735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1144.2654, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1045.7115, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1122.3628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1056.5010, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1130.7910, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1077.0383, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1148.8594, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(956.0430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1025.2360, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1019.7205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1092.3884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1038.2139, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1109.2557, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(878.5916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(947.1006, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1037.8606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1110.5182, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1003.8604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1070.5518, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1104.0610, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1178.5576, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(972.3821, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1044.8733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(965.5560, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1038.6438, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1039.1871, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1110.2662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1040.2729, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1106.5822, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(940.6398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1009.5864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(945.3187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1015.5222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1067.8439, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1134.0563, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(912.6954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(977.8159, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(954.6116, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1019.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1022.1723, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1087.2704, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(964.0294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1027.6620, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(881.3408, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(945.8864, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(928.7826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(987.7222, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(933.3661, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(988.3705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1037.0795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1098.3433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1035.6908, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1098.8446, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1013.3410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1074.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(959.7156, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1017.8792, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1035.2678, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1094.2523, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(878.2758, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(937.4664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(925.7672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(983.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(976.7034, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1037.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1008.3469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1068.7540, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1041.9214, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1102.0630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(863.2521, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(926.8397, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(986.9934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1040.3567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1011.5276, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1068.2919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(964.8283, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1027.0366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(949.9230, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1011.6579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(958.2913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1014.1138, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1030.7622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1083.9750, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(988.9409, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1048.8992, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(1005.0546, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1060.0439, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(972.0200, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1026.5413, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(961.8495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1018.0812, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(953.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1008.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(903.1290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(962.0894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(881.5914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(938.0346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(963.1296, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1011.8421, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(896.7297, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(950.2950, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(915.5118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(967.1171, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(878.2681, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(934.4111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(831.3767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(880.2183, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(905.9470, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(959.2010, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(930.5091, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(977.6107, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(775.3183, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(825.4264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(985.3122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(1037.1373, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(847.0291, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(897.4227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(932.3083, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(978.6827, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(866.2862, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(915.5729, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(924.2339, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(976.7179, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(762.1178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(808.2552, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(942.3275, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(984.3878, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(903.5527, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(950.9868, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(878.1008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(930.4319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(802.8488, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(846.2152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(787.9396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(829.5144, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(861.1934, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(899.7208, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(935.5789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(977.9420, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(756.0096, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(798.6453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(937.9290, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(982.2662, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(847.9293, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(895.9155, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(885.5574, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(933.7933, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(822.2124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(869.1459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(848.4454, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(894.9860, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(911.3256, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(956.3191, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(811.7086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(850.8990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(812.6721, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(847.2719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(763.2210, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(802.8646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(788.7352, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(837.9375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(752.6899, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(791.7520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(750.7731, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(788.6744, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(773.7431, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(809.9356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(883.0604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(927.8983, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(789.1772, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(825.4804, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(808.0262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(848.0024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(816.7849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(854.7528, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(870.2994, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(907.0934, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(830.9354, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(862.9641, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(900.4832, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(932.1832, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(794.5074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(829.6132, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(767.6876, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(805.6274, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(829.6324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(867.6896, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(842.0074, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(881.8909, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(724.7333, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(756.3738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(797.6858, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(831.6876, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(759.3903, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(796.0800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(811.4713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(849.5712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(691.3015, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(723.5549, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(767.9318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(796.4965, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(759.1343, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(795.8547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(800.9810, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(828.9260, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(679.7773, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(712.9658, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(743.7351, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(774.4269, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(910.3860, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(941.9705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(795.6009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(826.2925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(803.8063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(839.0680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(711.3915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(737.4537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(733.5834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(765.3810, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(786.3506, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(811.2297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(792.7425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(827.0694, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(923.9669, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(951.9061, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(724.2750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(755.3829, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(786.0844, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(818.9519, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(790.6441, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(814.1430, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(766.1936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(789.6456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(834.9013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(861.6166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(865.0485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(894.8840, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(724.3406, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(748.3115, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(847.2419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(875.0736, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(725.9637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(748.5543, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(692.0359, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(716.1547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(767.8933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(794.8322, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.9182, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(777.9235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(925.6453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(947.0858, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(861.3425, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(890.3303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(815.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(839.1204, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(841.9243, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(865.3500, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(787.2241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(808.6129, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.6187, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(776.1588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(677.9775, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(699.7158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(715.2526, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(733.0627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(750.9118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(775.2350, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(802.0665, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(820.2123, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(682.7394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(703.6229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(680.6752, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(700.2699, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(744.0184, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(764.5723, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(821.0957, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(841.8978, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(727.2604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(746.7037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(740.4396, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(757.6136, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(684.0808, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(704.7974, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(694.4102, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(712.2637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(877.5702, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(892.4807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(705.2455, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(726.3575, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(811.4575, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(827.5877, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(809.1705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(823.4166, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(821.8699, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(839.1348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(644.8251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(663.7227, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(761.4149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(778.9174, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(675.3833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(693.0517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(822.2914, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(841.8037, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(816.5247, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(832.6083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(716.5746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(734.9996, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(660.2012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(676.1788, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(639.0483, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(652.9286, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(664.3131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(679.4713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(678.0913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(696.9553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(760.4774, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(776.4929, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(653.0667, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(667.1196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(644.3714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(659.8555, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(854.5703, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(868.8106, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(761.4596, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(778.0083, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(728.3022, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(744.0298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(877.4371, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(894.9329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(915.6217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(930.4775, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(799.9796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(813.5709, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(738.6038, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(755.3034, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(698.9158, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(712.0386, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(759.5062, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(774.3997, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(740.0341, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(752.2200, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(721.8353, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(734.4501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(689.6511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(702.9435, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(738.3389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(752.3753, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.1295, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(721.6303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.4349, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(763.0417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(737.2053, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(750.9551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(647.8801, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(659.8524, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(794.9730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(808.1621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(763.0542, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(775.7517, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(927.2388, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(938.7262, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(663.2018, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(675.5884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(641.9192, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(654.1013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(736.0534, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(748.1791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(767.5188, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(779.2814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(799.8265, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(811.7886, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(848.7012, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(861.3925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(680.5043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(692.5276, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(739.5181, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(752.1499, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(677.9122, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(691.3644, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(705.1394, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(718.1696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(728.7305, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(740.2404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(680.9712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(692.8209, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.4004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(715.4680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(755.4812, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(765.4028, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(647.8068, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(655.8394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(748.3482, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(758.5428, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(789.2235, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(799.1302, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(716.1531, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(725.8506, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(621.8479, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(632.6429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.5495, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(716.0501, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(827.2419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(842.3561, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(702.0389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(711.6178, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(645.2241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(654.7074, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(698.4797, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(707.3148, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(755.7935, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(766.6240, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(687.4904, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(696.2986, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(664.5962, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(673.2255, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(667.7041, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(677.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(622.7169, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(631.0738, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(686.6611, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(696.7820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(758.1779, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(768.5520, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(729.4835, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(738.5831, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(690.9976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(699.9631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.9340, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(723.4578, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(704.5848, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(713.3615, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(676.0612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(686.6735, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(747.9480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(756.2290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(643.6969, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(651.0336, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(715.5266, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(723.5636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(765.8307, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(775.7114, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(773.9419, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(782.8404, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(721.8583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(730.9045, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(671.1737, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(680.9673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(717.9646, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(726.6597, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(750.0011, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(758.1391, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(744.9863, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(755.5372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(708.9255, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(717.1232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(843.0861, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(852.4250, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(809.5502, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(816.3105, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(693.8044, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(701.8953, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(771.0253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(778.0215, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.0300, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(757.6614, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(729.8024, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(739.4214, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(667.8901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(675.8465, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(739.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(748.8002, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(690.9744, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(699.8522, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(729.0322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(740.8344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(655.4557, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(663.3289, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.2432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(758.5800, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(669.3867, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(675.9410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(696.9569, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(703.4890, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(695.2539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(702.4577, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(789.6140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(796.6459, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(704.6030, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(714.8742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(699.8324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(707.8814, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(839.2642, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(846.0925, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.9695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(756.9772, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(732.1511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(739.3547, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(705.8469, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(714.3173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(726.3140, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(734.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(759.8795, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(766.2621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(830.4799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(838.9636, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(643.3251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(649.3954, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(760.3740, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(769.0674, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(646.2727, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(652.7382, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(694.2350, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(700.2867, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(817.6503, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(824.4855, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(838.5696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(848.0599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(843.0837, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(851.3912, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(697.1666, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(705.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(764.7278, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(770.2870, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(637.0005, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(644.4714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(774.9622, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(784.0664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(778.4637, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(784.4613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(616.7000, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(625.0299, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(714.6625, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(721.5759, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(673.7983, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(681.4181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(724.8553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(734.4531, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(735.9446, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(741.5099, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(693.8545, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(700.5449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(738.0627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(747.3639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(781.4933, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(790.5280, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(785.3098, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(791.8530, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(731.2076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(738.8691, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(640.7990, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(647.4075, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(700.7322, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(709.8630, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(692.3131, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(697.8781, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(756.1489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(762.8663, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(714.0577, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(719.7476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.0076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(711.8356, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(743.2728, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(751.3932, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(717.3883, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(724.4637, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(630.2732, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(636.0038, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(730.3111, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(739.6888, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(622.6319, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(629.7823, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(709.8824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(716.2195, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(696.3153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(702.6412, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(780.9086, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(785.8553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(663.1509, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(670.0287, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(748.7725, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(756.8098, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(732.5250, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(740.1526, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(702.3604, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(709.1029, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(801.0566, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(807.6165, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(728.1294, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(735.0961, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(675.3940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(682.8782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(744.0496, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(750.0264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(733.6189, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(739.6865, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(642.2239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(647.8035, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(722.5133, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(727.7551, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(613.3165, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(619.6218, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.7048, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(718.9785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(668.2921, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(676.2181, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(741.7130, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(746.5122, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(726.2084, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(733.0948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(775.8094, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(780.7457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(737.7930, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(744.2650, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(876.3631, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(881.4196, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(764.5253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(770.1596, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(758.6658, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(765.1915, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.9735, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(712.4285, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(733.2640, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(738.8119, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(726.3170, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(732.5656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(685.0056, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(692.1559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(782.3561, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(787.2714, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(660.7549, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(665.9847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(719.6064, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(725.1456, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(715.6321, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(721.3585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(623.0971, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(628.7151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(746.5884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(753.7880, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(814.0940, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(822.4503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(714.9966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(721.1480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(712.2966, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(718.5375, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(688.1606, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(694.7900, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(684.8424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(692.3408, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(761.7435, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(767.7891, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(714.3498, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(720.1158, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(717.9442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(723.8458, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(734.1063, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(740.7844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(773.7324, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(780.7480, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(709.8972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(715.3887, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(765.0583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(771.0951, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(742.3964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(747.6987, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(692.6013, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(698.7498, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(826.8985, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(832.7232, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(714.8239, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(722.8906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(740.7672, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(745.5032, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(812.8954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(818.3406, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(707.6769, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(713.6628, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(725.4585, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(731.2048, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(761.4006, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(768.4475, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(634.2288, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(640.0416, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(687.7516, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(693.4445, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(827.9077, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(833.5377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(659.6849, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(665.1440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(760.0824, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(764.5708, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(771.5493, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(776.7885, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(842.5430, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(847.4514, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(688.2076, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(694.4072, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(673.5674, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(679.5012, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(807.6095, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(813.1265, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(657.8423, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(663.6071, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(710.4668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(715.3264, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(698.2884, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(705.1733, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(687.7253, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(694.7017, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(761.6615, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(766.5266, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.5176, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(719.5318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(757.6027, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(765.3333, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(731.3834, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(736.1023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(653.1901, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(658.8449, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(819.0453, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(824.3003, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(769.2259, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(774.7111, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(674.0607, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(678.9883, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(729.3613, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(734.8686, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(766.1553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(773.5203, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(674.6912, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(683.6229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(697.4191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(703.0807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(727.1329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(733.0610, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(727.9008, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(734.1567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(682.2916, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(688.1761, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(654.5101, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(662.1807, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(750.2742, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(756.2898, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(620.3302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(626.0732, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(629.8173, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(634.7669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(772.7490, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(778.6091, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(762.7750, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(769.3782, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(765.3796, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(771.8108, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(714.0950, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(719.2631, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(709.5398, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(714.4400, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(815.8767, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(820.5785, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(744.2535, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(750.4344, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(748.8906, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(753.8766, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(664.4623, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(670.8583, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(736.9009, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(742.4495, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(788.3016, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(795.3760, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(642.3414, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(647.9407, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(699.9705, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(706.4647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(725.3197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(731.9598, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(764.1150, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(771.6730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(770.6833, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(775.5390, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(788.3540, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(792.9346, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(717.0093, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(722.1238, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(740.9926, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(746.0073, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(668.2355, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(673.4722, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(704.5519, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(709.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(698.0892, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(704.4081, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(650.6677, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(654.8417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(630.9497, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(634.7306, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(736.4675, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(741.5629, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(650.0050, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(655.1301, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(640.9594, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(646.0303, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(750.2087, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(756.1693, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(673.4227, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(679.6537, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(681.3684, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(689.1580, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(704.0847, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(709.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(717.6964, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(724.9377, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(718.7377, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(725.0588, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(674.5508, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(680.4387, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(695.6668, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(702.3036, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(701.2424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(706.9962, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(736.3137, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(742.3024, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(676.0928, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(682.3844, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(684.4099, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(691.0282, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(810.5118, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(816.4839, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(744.3635, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(749.4429, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(710.8746, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(716.5135, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(654.8799, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(662.4476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(666.9486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(674.3152, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(747.1251, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(753.9943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(662.1486, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(670.5298, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(730.3257, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(735.5948, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(683.6241, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(693.7795, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(674.3712, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(683.6820, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(674.3654, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(681.7705, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(729.7329, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(737.4383, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(678.6481, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(683.8070, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(636.5948, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(643.0721, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(678.7627, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(684.7297, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(684.5956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(690.7004, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(635.9713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(641.1680, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(642.8196, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(648.8041, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(709.1072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(715.9719, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(643.6553, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(650.0568, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.4793, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(712.8466, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(702.9539, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(708.3160, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(658.7805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(665.3290, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(660.3925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(665.7613, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(632.1449, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(636.8372, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(667.6346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(673.2585, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.1217, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(719.5833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(644.5886, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(653.6664, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(773.4717, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(779.5671, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(700.4991, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(706.9326, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(710.3004, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(715.9471, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(668.1129, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(673.0884, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(793.0225, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(799.1096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(725.6548, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(733.3647, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(742.7126, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(750.7742, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(648.9562, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(655.7112, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(668.4652, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(675.3229, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(645.1713, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(651.0920, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(615.8149, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(624.8325, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(600.4814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(606.4730, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(778.8105, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(783.9979, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(737.6389, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(743.8564, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(616.8571, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(622.6151, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(631.4401, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(638.2943, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(693.8925, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(699.5318, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(662.3205, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(667.9755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(642.9289, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(647.9904, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(790.3555, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(795.8621, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(669.9072, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(678.6423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(688.2805, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(695.7675, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(647.9281, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(655.1737, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(658.8789, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(665.3639, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(612.4853, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(620.3329, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(731.9234, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(739.4109, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(721.6191, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(728.0117, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(624.9463, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(632.1451, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(669.8693, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(677.3417, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(645.5695, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(651.6567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(671.5392, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(677.3767, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(743.9485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(750.2866, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(759.5346, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(766.1859, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(722.7765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(729.4433, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(682.3730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(688.6833, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(674.9738, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(680.8058, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(684.4432, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(691.1894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(707.4583, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(713.3848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(701.9913, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(707.0085, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(652.7489, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(656.8645, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(655.9523, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(661.3599, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(749.4857, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(755.5388, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(762.3226, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(769.4361, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(690.9826, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(697.5894, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(696.0840, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(703.6842, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(774.1124, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(781.4343, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(720.5803, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(726.7469, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(764.2936, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(769.3712, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.3043, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(719.4713, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(663.0186, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(668.9366, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(845.3630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(851.6237, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(751.4620, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(758.2692, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(710.0473, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(716.0922, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.5448, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(719.9023, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(746.5612, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(752.6627, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(726.2897, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(732.1414, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(646.2976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(654.7225, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(693.9424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(699.5940, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.2660, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(718.3572, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(794.4872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(799.9927, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(695.0814, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(701.1656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(684.1342, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(690.0567, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(689.6254, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(695.7319, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(769.1332, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(775.0587, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(666.1424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(675.4192, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(679.9198, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(686.5410, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(630.8709, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(638.2848, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(653.5872, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(659.9505, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(727.7262, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(733.9919, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(752.6989, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(758.9847, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(686.3142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(693.5067, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(709.5422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(717.9696, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(713.8422, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(721.4462, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(715.3424, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(720.2235, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(660.3145, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(666.6364, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(707.5438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(712.4669, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(682.3385, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(688.5562, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(625.6369, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(632.4747, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(647.2856, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(653.4643, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(659.9323, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(667.9348, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(578.3450, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(582.9230, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(746.1434, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(752.1460, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(679.9696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(686.8281, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(648.9459, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(654.9213, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(747.7151, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(755.5236, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(646.6804, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(653.8755, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(648.7153, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(654.9173, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(650.5194, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(655.8836, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(785.6492, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(791.8871, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(654.6475, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(659.8427, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(619.1220, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(627.5553, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(696.7172, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(700.9423, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(761.1484, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(767.3116, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(616.8142, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(622.5689, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(628.9055, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(636.6307, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(705.4915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(710.2481, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(727.3730, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(732.4805, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(702.1651, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(708.4559, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(584.9065, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(594., device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(635.4178, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(641.0646, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(726.3956, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(731.7791, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(636.1972, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(641.9279, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(701.6550, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(710.6332, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(672.5410, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(680.0809, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(741.4386, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(748.3776, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(722.8630, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(728.4525, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(716.0485, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(720.2440, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(646.8597, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(653.2960, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(780.1193, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(787.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(727.3442, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(732.7579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(757.0850, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(765.3872, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(723.1587, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(729.0013, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(744.0811, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(750.9981, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(770.4438, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(778.9384, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(652.0047, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(657.5453, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(641.6670, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(649.9660, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(759.4603, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(765.4457, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(723.5800, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(728.5825, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.6819, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(715.0161, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(853.4879, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(859.1579, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(742.7197, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(747.5846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(678.7676, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(686.1492, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(709.6511, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(714.0783, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(645.5504, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(652.2476, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(594.0696, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(598.8673, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(676.6915, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(684.0020, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(675.4954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(680.5424, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(732.0878, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(739.0001, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(665.3318, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(671.7764, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(653.0510, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(657.8516, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(686.8714, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(691.9503, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(719.3480, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(724.6697, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(681.4954, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(687.3278, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(815.7629, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(820.7394, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(692.7302, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(698.6906, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(706.7765, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(711.7616, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(650.4512, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(656.6473, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(681.1907, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(686.3656, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(644.9536, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(652.1990, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(658.0836, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(664.7821, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(716.9579, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(724.1931, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(658.6586, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(665.8849, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(685.8292, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(692.2354, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/optim/lr_scheduler.py:156: UserWarning: The epoch parameter in `scheduler.step()` was not necessary and is being deprecated where possible. Please use `scheduler.step()` to step the scheduler. During the deprecation, if epoch is different from None, the closed form is used instead of the new chainable form, where available. Please open an issue if you are unable to replicate your use case: https://github.com/pytorch/pytorch/issues/new/choose.\n",
      "  warnings.warn(EPOCH_DEPRECATION_WARNING, UserWarning)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1\n",
      "tensor(696.3976, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(701.6707, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(682.1058, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(687.1846, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(679.1902, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(683.5096, device='cuda:0', grad_fn=<AddBackward0>)\n",
      "loss1\n",
      "tensor(593.0838, device='cuda:0', grad_fn=<MulBackward0>)\n",
      "loss2\n",
      "tensor(598.0825, device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Detected KeyboardInterrupt, attempting graceful shutdown ...\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'exit' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:47\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mstrategy\u001b[38;5;241m.\u001b[39mlauncher\u001b[38;5;241m.\u001b[39mlaunch(trainer_fn, \u001b[38;5;241m*\u001b[39margs, trainer\u001b[38;5;241m=\u001b[39mtrainer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m---> 47\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtrainer_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m _TunerExitException:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:574\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    568\u001b[0m ckpt_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_checkpoint_connector\u001b[38;5;241m.\u001b[39m_select_ckpt_path(\n\u001b[1;32m    569\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mfn,\n\u001b[1;32m    570\u001b[0m     ckpt_path,\n\u001b[1;32m    571\u001b[0m     model_provided\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    572\u001b[0m     model_connected\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlightning_module \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    573\u001b[0m )\n\u001b[0;32m--> 574\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mckpt_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstopped\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:981\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m    978\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    979\u001b[0m \u001b[38;5;66;03m# RUN THE TRAINER\u001b[39;00m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[0;32m--> 981\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_stage\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    983\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n\u001b[1;32m    984\u001b[0m \u001b[38;5;66;03m# POST-Training CLEAN UP\u001b[39;00m\n\u001b[1;32m    985\u001b[0m \u001b[38;5;66;03m# ----------------------------\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:1025\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1024\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mautograd\u001b[38;5;241m.\u001b[39mset_detect_anomaly(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1025\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:205\u001b[0m, in \u001b[0;36m_FitLoop.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_start()\n\u001b[0;32m--> 205\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    206\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:363\u001b[0m, in \u001b[0;36m_FitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    362\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_fetcher \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 363\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mepoch_loop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data_fetcher\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:140\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.run\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madvance\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata_fetcher\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    141\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mon_advance_end(data_fetcher)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/training_epoch_loop.py:250\u001b[0m, in \u001b[0;36m_TrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mlightning_module\u001b[38;5;241m.\u001b[39mautomatic_optimization:\n\u001b[1;32m    249\u001b[0m     \u001b[38;5;66;03m# in automatic optimization, there can only be one optimizer\u001b[39;00m\n\u001b[0;32m--> 250\u001b[0m     batch_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautomatic_optimization\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:190\u001b[0m, in \u001b[0;36m_AutomaticOptimization.run\u001b[0;34m(self, optimizer, batch_idx, kwargs)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# BACKWARD PASS\u001b[39;00m\n\u001b[1;32m    187\u001b[0m \u001b[38;5;66;03m# ------------------------------\u001b[39;00m\n\u001b[1;32m    188\u001b[0m \u001b[38;5;66;03m# gradient update with accumulated gradients\u001b[39;00m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 190\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    192\u001b[0m result \u001b[38;5;241m=\u001b[39m closure\u001b[38;5;241m.\u001b[39mconsume_result()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/loops/optimization/automatic.py:268\u001b[0m, in \u001b[0;36m_AutomaticOptimization._optimizer_step\u001b[0;34m(self, batch_idx, train_step_and_backward_closure)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[38;5;66;03m# model hook\u001b[39;00m\n\u001b[0;32m--> 268\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_lightning_module_hook\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43moptimizer_step\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_epoch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_idx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_step_and_backward_closure\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    275\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m should_accumulate:\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:167\u001b[0m, in \u001b[0;36m_call_lightning_module_hook\u001b[0;34m(trainer, hook_name, pl_module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m trainer\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mprofile(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[LightningModule]\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpl_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhook_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 167\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m \u001b[38;5;66;03m# restore current_fx when nested context\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/core/module.py:1306\u001b[0m, in \u001b[0;36mLightningModule.optimizer_step\u001b[0;34m(self, epoch, batch_idx, optimizer, optimizer_closure)\u001b[0m\n\u001b[1;32m   1282\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Override this method to adjust the default way the :class:`~pytorch_lightning.trainer.trainer.Trainer` calls\u001b[39;00m\n\u001b[1;32m   1283\u001b[0m \u001b[38;5;124;03mthe optimizer.\u001b[39;00m\n\u001b[1;32m   1284\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1304\u001b[0m \n\u001b[1;32m   1305\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1306\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer_closure\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/core/optimizer.py:153\u001b[0m, in \u001b[0;36mLightningOptimizer.step\u001b[0;34m(self, closure, **kwargs)\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_strategy \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 153\u001b[0m step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_strategy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_optimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_on_after_step()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/strategies/strategy.py:238\u001b[0m, in \u001b[0;36mStrategy.optimizer_step\u001b[0;34m(self, optimizer, closure, model, **kwargs)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(model, pl\u001b[38;5;241m.\u001b[39mLightningModule)\n\u001b[0;32m--> 238\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision_plugin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclosure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclosure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/plugins/precision/amp.py:94\u001b[0m, in \u001b[0;36mMixedPrecision.optimizer_step\u001b[0;34m(self, optimizer, model, closure, **kwargs)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m skip_unscaling:\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;66;03m# note: the scaler will skip the `optimizer.step` if nonfinite gradients are found\u001b[39;00m\n\u001b[0;32m---> 94\u001b[0m     step_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:452\u001b[0m, in \u001b[0;36mGradScaler.step\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    448\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m (\n\u001b[1;32m    449\u001b[0m     \u001b[38;5;28mlen\u001b[39m(optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    450\u001b[0m ), \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo inf checks were recorded for this optimizer.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m--> 452\u001b[0m retval \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_opt_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    454\u001b[0m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstage\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m OptState\u001b[38;5;241m.\u001b[39mSTEPPED\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:349\u001b[0m, in \u001b[0;36mGradScaler._maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    348\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43moptimizer_state\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf_per_device\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvalues\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    350\u001b[0m     retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/torch/cuda/amp/grad_scaler.py:349\u001b[0m, in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    348\u001b[0m retval: Optional[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 349\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28msum\u001b[39m(\u001b[43mv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m optimizer_state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfound_inf_per_device\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    350\u001b[0m     retval \u001b[38;5;241m=\u001b[39m optimizer\u001b[38;5;241m.\u001b[39mstep(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39misdir(ssl_dir):\n\u001b[1;32m      3\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(ssl_dir)\n\u001b[0;32m----> 4\u001b[0m ssl_model \u001b[38;5;241m=\u001b[39m \u001b[43mlightning_models\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_clap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mssl_train_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mssl_val_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mmax_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mevery_n_epochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSSL\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msave_every_n_epochs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mprecision\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mprecision\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mssl_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m                                        \u001b[49m\u001b[43mif_profile\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mINFO\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mif_profile\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/code/clap/model/lightning_models.py:246\u001b[0m, in \u001b[0;36mtrain_clap\u001b[0;34m(model, train_loader, val_loader, max_epochs, every_n_epochs, checkpoint_path, grad_accumulation_steps, num_nodes, gpus_per_node, strategy, precision, restart, if_profile)\u001b[0m\n\u001b[1;32m    244\u001b[0m         trainer\u001b[38;5;241m.\u001b[39mfit(model, train_loader,val_loader,ckpt_path\u001b[38;5;241m=\u001b[39mckpt_files[\u001b[38;5;241m0\u001b[39m])\n\u001b[1;32m    245\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 246\u001b[0m         \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    247\u001b[0m     model \u001b[38;5;241m=\u001b[39m CLAP\u001b[38;5;241m.\u001b[39mload_from_checkpoint(trained_filename) \u001b[38;5;66;03m# Load best checkpoint after training\u001b[39;00m\n\u001b[1;32m    248\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/trainer.py:538\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m=\u001b[39m TrainerStatus\u001b[38;5;241m.\u001b[39mRUNNING\n\u001b[1;32m    537\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m--> 538\u001b[0m \u001b[43mcall\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_and_handle_interrupt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    539\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fit_impl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_dataloaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdatamodule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mckpt_path\u001b[49m\n\u001b[1;32m    540\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/trainer/call.py:64\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(launcher, _SubprocessScriptLauncher):\n\u001b[1;32m     63\u001b[0m         launcher\u001b[38;5;241m.\u001b[39mkill(_get_sigkill_signal())\n\u001b[0;32m---> 64\u001b[0m     \u001b[43mexit\u001b[49m(\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exception:\n\u001b[1;32m     67\u001b[0m     _interrupt(trainer, exception)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'exit' is not defined"
     ]
    }
   ],
   "source": [
    "ssl_dir = os.path.join(config.loc,\"ssl\")\n",
    "if not os.path.isdir(ssl_dir):\n",
    "    os.makedirs(ssl_dir)\n",
    "ssl_model = lightning_models.train_clap(model=ssl_model, \n",
    "                                        train_loader = ssl_train_loader,\n",
    "                                        val_loader = ssl_val_loader,\n",
    "                                        max_epochs=config.SSL[\"n_epochs\"],\n",
    "                                        every_n_epochs = config.SSL[\"save_every_n_epochs\"],\n",
    "                                        precision = config.INFO[\"precision\"],\n",
    "                                        checkpoint_path=ssl_dir,\n",
    "                                        if_profile=config.INFO[\"if_profile\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b163edae-f73e-4982-a53d-89e00a2d031c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ssl_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1afc30c-f70e-4a4a-b703-93873d8644ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.1/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.2/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/lc/lr_0.3/best_val.ckpt, loading...\n"
     ]
    }
   ],
   "source": [
    "lc_batch_size = config.LC[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "data_info = {\"dataset\":config.DATA[\"dataset\"],\"batch_size\":lc_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "            \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "# need to specify the location of the data for imagenet\n",
    "if \"IMAGENET1K\" in config.DATA[\"dataset\"]:\n",
    "    data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "    data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "\n",
    "lc_train_loader,lc_test_loader,lc_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                         standardized_to_imagenet=config.LC[\"standardize_to_imagenet\"],\n",
    "                                                                         prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "# root directory for linear classification\n",
    "lc_dir = os.path.join(config.loc,\"lc\")\n",
    "if not os.path.isdir(lc_dir):\n",
    "    os.makedirs(lc_dir)\n",
    "if \"lr_sweep\" in config.LC:\n",
    "    lr_list = config.LC[\"lr_sweep\"]\n",
    "else:\n",
    "    lr_list = [config.LC[\"lr\"]]\n",
    "# sweep learning rates\n",
    "best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "for lr in lr_list:\n",
    "    lc_sub_dir = os.path.join(lc_dir,\"lr_{}\".format(lr))\n",
    "    os.makedirs(lc_sub_dir,exist_ok=True)\n",
    "    if config.LC[\"lr_scale\"] == \"linear\":\n",
    "        lc_lr = lr*config.LC[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "    elif config.LC[\"lr_scale\"] == \"sqrt\":\n",
    "        lc_lr = lr*math.sqrt(config.LC[\"batch_size\"]) # lr ~ 0.05\n",
    "    # load the backbone from the check point\n",
    "    best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "    ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "    ssl_model.backbone.remove_projection_head()\n",
    "\n",
    "    lc_model = lightning_models.LinearClassification(\n",
    "                 backbone = ssl_model.backbone,\n",
    "                 in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                 out_dim = config.LC[\"output_dim\"],\n",
    "                 use_batch_norm = config.LC[\"use_batch_norm\"],\n",
    "                 optim_name = config.LC[\"optimizer\"],\n",
    "                 scheduler_name = config.LC[\"lr_scheduler\"],\n",
    "                 lr = lc_lr, \n",
    "                 momentum = config.LC[\"momentum\"],\n",
    "                 weight_decay = config.LC[\"weight_decay\"],\n",
    "                 n_epochs = config.LC[\"n_epochs\"])\n",
    "    \n",
    "    lc_model = lightning_models.train_lc(linear_model = lc_model,\n",
    "            train_loader = lc_train_loader,\n",
    "            test_loader = lc_test_loader,\n",
    "            val_loader = lc_val_loader,\n",
    "            max_epochs = config.LC[\"n_epochs\"],\n",
    "            every_n_epochs = config.LC[\"save_every_n_epochs\"],\n",
    "            checkpoint_path = lc_sub_dir,\n",
    "            precision = config.INFO[\"precision\"],\n",
    "            restart = config.LC[\"restart_training\"])\n",
    "    # get the best performed one\n",
    "    with open(os.path.join(lc_sub_dir,\"results.json\")) as f:\n",
    "        result = json.load(f)\n",
    "    if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "        best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "        best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "        best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        best[\"best_model_dir\"] = lc_sub_dir\n",
    "#save the information about the best model\n",
    "with open(os.path.join(lc_dir,\"results.json\"),\"w\") as f:\n",
    "    json.dump(best,f,indent=4)  \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6823b6cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./simulation_imagenet/lc'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lc_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88681e77-5ab3-4401-8d14-34606a63fc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.1/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.2/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-1percent/lr_0.3/best_val.ckpt, loading...\n",
      "Found pretrained model at ./simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.1/best_val.ckpt, loading...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4070 Laptop GPU') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/lightning_fabric/loggers/csv_logs.py:268: Experiment logs directory ./simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.2/logs/csv/version_0 exists and is not empty. Previous log files in this directory will be deleted when the new ones are saved!\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.2 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 27.7 M | train\n",
      "1 | linear_net | BnLinearNet | 2.1 M  | train\n",
      "---------------------------------------------------\n",
      "29.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 M    Total params\n",
      "119.030   Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b3ab7adb337646ae9e7acbcb2fa37553",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f164359336b471eb21ca5c62e8a70da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "     batch_test_acc1       0.0013404289493337274\n",
      "     batch_test_acc5        0.00616197194904089\n",
      "     batch_test_loss         8.386237144470215\n",
      "        test_acc1          0.0013404289493337274\n",
      "        test_acc5           0.00616197194904089\n",
      "        test_loss            8.386237144470215\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/richard/miniconda3/envs/dl_env/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:654: Checkpoint directory /home/richard/Documents/code/clap/simulation_imagenet/semisl-IMAGENET1K-10percent/lr_0.3 exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name       | Type        | Params | Mode \n",
      "---------------------------------------------------\n",
      "0 | backbone   | BackboneNet | 27.7 M | train\n",
      "1 | linear_net | BnLinearNet | 2.1 M  | train\n",
      "---------------------------------------------------\n",
      "29.8 M    Trainable params\n",
      "0         Non-trainable params\n",
      "29.8 M    Total params\n",
      "119.030   Total estimated model params size (MB)\n",
      "156       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |                                        | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb217f39bf3e4dda931b17222be0b107",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |                                               | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |                                             | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=2` reached.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2541fb439a19467fb2a7db0040b65332",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Testing: |                                                | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "       Test metric             DataLoader 0\n",
      "\n",
      "     batch_test_acc1       0.001260403310880065\n",
      "     batch_test_acc5       0.004921575076878071\n",
      "     batch_test_loss         9.744197845458984\n",
      "        test_acc1          0.001260403310880065\n",
      "        test_acc5          0.004921575076878071\n",
      "        test_loss            9.744195938110352\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Fine-tune or semi-supervised learning\n",
    "if len(config.SemiSL) > 0:\n",
    "    semisl_batch_size = config.SemiSL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "    for dataset in [\"IMAGENET1K-1percent\",\"IMAGENET1K-10percent\"]:\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        # add the location for imagenet dataset\n",
    "        data_info[\"imagenet_train_dir\"] = config.DATA[\"imagenet_train_dir\"]\n",
    "        data_info[\"imagenet_val_dir\"] = config.DATA[\"imagenet_val_dir\"]\n",
    "        \n",
    "        semisl_train_loader,semisl_test_loader,semisl_val_loader = data_utils.get_dataloader(data_info,semisl_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.SemiSL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        semisl_dir = os.path.join(config.loc,\"semisl-\"+dataset)\n",
    "        if not os.path.isdir(semisl_dir):\n",
    "            os.makedirs(semisl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            semisl_sub_dir = os.path.join(semisl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(semisl_sub_dir,exist_ok=True)\n",
    "            if config.SemiSL[\"lr_scale\"] == \"linear\":\n",
    "                semisl_lr = lr*config.SemiSL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.SemiSL[\"lr_scale\"] == \"sqrt\":\n",
    "                semisl_lr = lr*math.sqrt(config.SemiSL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "            # load the best linear classifier from the checkpoint\n",
    "            with open(os.path.join(lc_dir,\"results.json\")) as f:\n",
    "                results = json.load(f)\n",
    "                best_lc_dir = results[\"best_model_dir\"] \n",
    "            lc_model = lightning_models.LinearClassification.load_from_checkpoint(os.path.join(best_lc_dir,\"best_val.ckpt\"),backbone = ssl_model.backbone)\n",
    "            semisl_model = lightning_models.FineTune(backbone = ssl_model.backbone,\n",
    "                    linear_net= lc_model.linear_net,\n",
    "                    optim_name = config.SemiSL[\"optimizer\"],\n",
    "                    lr = semisl_lr, \n",
    "                    momentum = config.SemiSL[\"momentum\"],\n",
    "                    weight_decay = config.SemiSL[\"weight_decay\"],\n",
    "                    n_epochs = config.SemiSL[\"n_epochs\"])\n",
    "            semisl_model = lightning_models.train_finetune(\n",
    "                    finetune_model = semisl_model,\n",
    "                    train_loader = semisl_test_loader,\n",
    "                    test_loader = semisl_test_loader,\n",
    "                    val_loader = semisl_val_loader,\n",
    "                    max_epochs = config.SemiSL[\"n_epochs\"],\n",
    "                    every_n_epochs = config.SemiSL[\"save_every_n_epochs\"],\n",
    "                    checkpoint_path = semisl_sub_dir,\n",
    "                    precision= config.INFO[\"precision\"],\n",
    "                    restart = config.SemiSL[\"restart_training\"])\n",
    "            # get the best performed one\n",
    "            with open(os.path.join(semisl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "                best[\"best_model_dir\"] = semisl_sub_dir\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(semisl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2438876b-2b1f-46c4-b757-3ec4a21db478",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'config' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Transfer learning(freeze backbone)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[43mconfig\u001b[49m\u001b[38;5;241m.\u001b[39mTL) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m      3\u001b[0m     tl_output_dim \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m100\u001b[39m,\n\u001b[1;32m      4\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m101\u001b[39m,\n\u001b[1;32m      5\u001b[0m                     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m:\u001b[38;5;241m102\u001b[39m}\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCIFAR100\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFOOD101\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFLOWERS102\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "\u001b[0;31mNameError\u001b[0m: name 'config' is not defined"
     ]
    }
   ],
   "source": [
    "# Transfer learning(freeze backbone)\n",
    "if len(config.TL) > 0:\n",
    "    tl_output_dim = {\"CIFAR100\":100,\n",
    "                    \"FOOD101\":101,\n",
    "                    \"FLOWERS102\":102}\n",
    "    for dataset in [\"CIFAR100\",\"FOOD101\",\"FLOWERS102\"]:\n",
    "        tl_batch_size = config.TL[\"batch_size\"] // (config.INFO[\"num_nodes\"]*config.INFO[\"gpus_per_node\"])\n",
    "        data_info = {\"dataset\":dataset,\"batch_size\":semisl_batch_size,\"n_views\":1,\"augmentations\":[\"RandomResizedCrop\",\"RandomHorizontalFlip\"],\n",
    "                 \"crop_size\":config.DATA[\"crop_size\"],\"crop_min_scale\":0.08,\"crop_max_scale\":1.0,\"hflip_prob\":0.5}\n",
    "        tl_train_loader,tl_test_loader,tl_val_loader = data_utils.get_dataloader(data_info,lc_batch_size,num_workers=config.INFO[\"cpus_per_gpu\"],\n",
    "                                                                                 standardized_to_imagenet=config.TL[\"standardize_to_imagenet\"],\n",
    "                                                                                 prefetch_factor=config.INFO[\"prefetch_factor\"])\n",
    "        tl_dir = os.path.join(config.loc,\"tl-\"+dataset)\n",
    "        if not os.path.isdir(tl_dir):\n",
    "            os.makedirs(tl_dir)\n",
    "        if \"lr_sweep\" in config.SemiSL:\n",
    "            lr_list = config.SemiSL[\"lr_sweep\"]\n",
    "        else:\n",
    "            lr_list = [config.SemiSL[\"lr\"]]\n",
    "        # sweep learning rates\n",
    "        best = {\"best_test_acc1\":0.0,\"best_test_acc5\":0.0,\"best_test_loss\":0.0,\"best_model_dir\":\"none\"}\n",
    "        for lr in lr_list:\n",
    "            tl_sub_dir = os.path.join(tl_dir,\"lr_{}\".format(lr))\n",
    "            os.makedirs(tl_sub_dir,exist_ok=True)\n",
    "            if config.TL[\"lr_scale\"] == \"linear\":\n",
    "                tl_lr = lr*config.TL[\"batch_size\"]/256.0 # lr ~ 0.1\n",
    "            elif config.TL[\"lr_scale\"] == \"sqrt\":\n",
    "                tl_lr = lr*math.sqrt(config.TL[\"batch_size\"]) # lr ~ 0.05\n",
    "            # load the backbone from the checkpoint\n",
    "            best_ssl_ckpt = os.path.join(ssl_dir,\"best_val.ckpt\")\n",
    "            ssl_model = lightning_models.CLAP.load_from_checkpoint(best_ssl_ckpt)\n",
    "            ssl_model.backbone.remove_projection_head()\n",
    "        \n",
    "            tl_model = lightning_models.LinearClassification(\n",
    "                    backbone = ssl_model.backbone,\n",
    "                    in_dim = config.SSL[\"backbone_out_dim\"],\n",
    "                    out_dim = tl_output_dim[dataset],\n",
    "                    use_batch_norm = config.TL[\"use_batch_norm\"],\n",
    "                    optim_name = config.TL[\"optimizer\"],\n",
    "                    lr = tl_lr, \n",
    "                    scheduler_name= config.TL[\"lr_scheduler\"],\n",
    "                    momentum = config.TL[\"momentum\"],\n",
    "                    weight_decay = config.TL[\"weight_decay\"],\n",
    "                    n_epochs = config.TL[\"n_epochs\"])\n",
    "\n",
    "            tl_model = lightning_models.train_lc(\n",
    "                    linear_model = tl_model,\n",
    "                    train_loader = tl_train_loader,\n",
    "                    val_loader = tl_val_loader,\n",
    "                    test_loader = tl_test_loader,\n",
    "                    every_n_epochs = config.TL[\"save_every_n_epochs\"],\n",
    "                    max_epochs = config.TL[\"n_epochs\"],\n",
    "                    precision = config.INFO[\"precision\"],\n",
    "                    checkpoint_path = tl_sub_dir,\n",
    "                    restart = config.LC[\"restart_training\"]) \n",
    "                        # get the best performed one\n",
    "            with open(os.path.join(tl_sub_dir,\"results.json\")) as f:\n",
    "                result = json.load(f)\n",
    "            if result[\"test_acc1\"] > best[\"best_test_acc1\"]:\n",
    "                best[\"best_test_acc1\"] = result[\"test_acc1\"] \n",
    "                best[\"best_test_acc5\"] = result[\"test_acc5\"] \n",
    "                best[\"best_test_loss\"] = result[\"test_loss\"]\n",
    "        #save the information about the best model\n",
    "        with open(os.path.join(tl_dir,\"results.json\"),\"w\") as f:\n",
    "            json.dump(best,f,indent=4)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fae7a09-5dca-41ef-8191-59393d06a19d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
