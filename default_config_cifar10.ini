[INFO]
num_nodes = 1
gpus_per_node = 1
num_workers = 1
precision = 16-mixed

[DATA]
dataset = CIFAR10
n_views = 10
augmentations=RandomResizeCrop,GaussianBlur,RandomGrayscale,ColorJitter,RandomHorizontalFlip
crop_size = 32
crop_min_scale = 0.08
crop_max_scale = 1.0
hflip_prob = 0.5
blur_kernel_size = 1
blur_prob = 0.5
grayscale_prob = 0.2
jitter_brightness = 0.8
jitter_contrast = 0.8
jitter_saturation = 0.8
jitter_hue = 0.2
jitter_prob = 0.8

[SSL]
backbone = resnet18
backbone_out_dim = 2048
use_projection_header = yes
proj_out_dim = 256
optimizer = LARS
lr = 0.1
lr_scale = linear
momentum = 0.99
weight_decay = 1e-4
;for LARS optimizers, if not LARS then it is redandunt
lars_eta = 0.1 
loss_function = EllipsoidPackingLoss
lw0 = 1.0
lw1 = 1.0
lw2 = 1.0
rs = 3.0
warmup_epochs = 1
n_epochs =  10
batch_size = 128
save_every_n_epochs = 10
[LC]
output_dim = 10
optimizer = SGD
use_batch_norm = no
lr = 0.01
lr_scale = linear
weight_decay = 1e-4
momentum = 0.99
loss_function = CrossEntropyLoss
n_epochs = 0
batch_size = 128
;training_mode = load_last_pretrained_epoch
training_mode = scan_pretrained_epochs
[IO]
restart = yes

; some notes
; solo-learn is good reference for hyperparameters
; lr ~ batch_size/256

